{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smybilginn/neural_networks_midterm_assignment/blob/main/ysa_vize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7uumG0F72xr"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import accuracy_score , confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Kod AÃ§Ä±klamasÄ±\n",
        "\n",
        "Bu hÃ¼crede proje boyunca kullanÄ±lacak temel kÃ¼tÃ¼phaneler iÃ§e aktarÄ±lmaktadÄ±r:\n",
        "\n",
        "**load_breast_cancer**: Scikit-learn iÃ§indeki hazÄ±r meme kanseri veri setini yÃ¼klemek iÃ§in kullanÄ±lÄ±r.\n",
        "\n",
        "**accuracy_score ve confusion_matrix**: Modelin performansÄ±nÄ± Ã¶lÃ§mek iÃ§in doÄŸruluk oranÄ± ve karÄ±ÅŸÄ±klÄ±k matrisi hesaplamada kullanÄ±lÄ±r.\n",
        "\n",
        "**train_test_split**: Veri setini eÄŸitim ve test olarak ikiye ayÄ±rmaya yarar.\n",
        "\n",
        "**StandardScaler**: Ã–zellikleri standart Ã¶lÃ§eklemeye tabi tutarak modelin daha saÄŸlÄ±klÄ± Ã¶ÄŸrenmesini saÄŸlar.\n",
        "\n",
        "**pandas (pd)**: Veri analizi ve DataFrame iÅŸlemleri iÃ§in kullanÄ±lÄ±r.\n",
        "\n",
        "**numpy (np)**: SayÄ±sal hesaplamalar ve dizi iÅŸlemleri iÃ§in kullanÄ±lÄ±r.\n",
        "\n",
        "**matplotlib.pyplot (plt)**: Grafik ve gÃ¶rselleÅŸtirme iÅŸlemlerinde kullanÄ±lÄ±r."
      ],
      "metadata": {
        "id": "dPdGXMl4mOmP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ua6nQL_s9EK6"
      },
      "outputs": [],
      "source": [
        "#1.2\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "# Ã–zellik (feature) verilerini ve sÃ¼tun isimlerini kullanarak bir DataFrame oluÅŸturuyoruz\n",
        "df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
        "\n",
        "# 'target' sÃ¼tunu olarak sÄ±nÄ±f etiketlerini (0 = malign, 1 = benign) ekliyoruz\n",
        "df['target'] = cancer.target\n",
        "\n",
        "#\tX (Ã¶zellikler) ve y (hedef) deÄŸiÅŸkenlerini ayÄ±rÄ±yoruz\n",
        "X = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
        "y = pd.Series(cancer.target, name='target')\n",
        "\n",
        "# Ä°lk 5 satÄ±rÄ± gÃ¶steriyoruz\n",
        "print(df.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bu bÃ¶lÃ¼mde Breast Cancer veri seti yÃ¼klenmiÅŸ ve iÅŸlenebilir bir DataFrameâ€™e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸtÃ¼r:\n",
        "\n",
        "load_breast_cancer() fonksiyonu ile hazÄ±r meme kanseri veri seti projeye aktarÄ±lÄ±r.\n",
        "\n",
        "Veri setindeki Ã¶zellikler (cancer.data) ve bu Ã¶zelliklerin isimleri (cancer.feature_names) kullanÄ±larak bir DataFrame (df) oluÅŸturulur.\n",
        "\n",
        "Veri setinin sÄ±nÄ±f etiketleri olan target deÄŸeri (0 = malign, 1 = benign) DataFrameâ€™e ek bir sÃ¼tun olarak eklenir.\n",
        "\n",
        "Modelde girdi olarak kullanÄ±lacak X (Ã¶zellikler) ve Ã§Ä±ktÄ± olarak kullanÄ±lacak y (hedef sÄ±nÄ±f) deÄŸiÅŸkenleri ayrÄ± olarak tanÄ±mlanÄ±r.\n",
        "\n",
        "Son olarak veri setinin yapÄ±sÄ±nÄ± gÃ¶rmek iÃ§in ilk 5 satÄ±r (df.head()) ekrana yazdÄ±rÄ±lÄ±r."
      ],
      "metadata": {
        "id": "G2fLUQhams24"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24Rn2DzF_cff"
      },
      "outputs": [],
      "source": [
        "#2. Veri Seti Kalite Kontrolleri\n",
        "# 2.1 Eksik deÄŸer kontrolÃ¼\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"Eksik deÄŸer sayÄ±sÄ± her sÃ¼tunda:\\n\", missing_values)\n",
        "\n",
        "# 2.2. Eksik deÄŸer varsa doldurma (Ã¶rnek: ortalama ile doldurma)\n",
        "# Bu veri setinde eksik yok ama kod genel kullanÄ±m iÃ§in:\n",
        "df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "# Kontrol\n",
        "print(\"\\nEksik deÄŸer kontrolÃ¼ sonrasÄ±:\\n\", df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Veri Seti Kalite Kontrolleri\n",
        "###2.1 Eksik DeÄŸer KontrolÃ¼\n",
        "\n",
        "Bu adÄ±mda veri setindeki eksik deÄŸerler incelenmiÅŸtir:\n",
        "\n",
        "df.isnull().sum() komutu her sÃ¼tundaki eksik deÄŸer sayÄ±sÄ±nÄ± hesaplar.\n",
        "\n",
        "SonuÃ§lar ekrana yazdÄ±rÄ±larak hangi deÄŸiÅŸkenlerde eksik veri olup olmadÄ±ÄŸÄ± kontrol edilir.\n",
        "\n",
        "Bu veri setinde eksik deÄŸer bulunmadÄ±ÄŸÄ±ndan veri temizleme adÄ±mÄ± zorunlu deÄŸildir.\n",
        "\n",
        "###2.2 Eksik DeÄŸerleri Doldurma (Genel KullanÄ±m Ä°Ã§in)\n",
        "\n",
        "Kodun bu kÄ±smÄ± Ã¶rnek amaÃ§lÄ±dÄ±r:\n",
        "\n",
        "df.fillna(df.mean(), inplace=True): Eksik deÄŸerlerin olmasÄ± durumunda, her sÃ¼tundaki ortalama deÄŸer ile doldurmayÄ± saÄŸlar.\n",
        "\n",
        "Breast Cancer veri setinde eksik deÄŸer olmadÄ±ÄŸÄ± iÃ§in bu iÅŸlem aslÄ±nda veri Ã¼zerinde bir deÄŸiÅŸiklik yaratmaz ama kodun yeniden kullanÄ±labilirliÄŸini artÄ±rÄ±r.\n",
        "\n",
        "Kontrol SonrasÄ±\n",
        "\n",
        "Eksik deÄŸer doldurma iÅŸleminden sonra tekrar kontrol edilerek tÃ¼m sÃ¼tunlarda eksik deÄŸer olup olmadÄ±ÄŸÄ± doÄŸrulanÄ±r."
      ],
      "metadata": {
        "id": "uWhQKEN-nWYO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3659ac7a"
      },
      "outputs": [],
      "source": [
        "# Her sÃ¼tun iÃ§in istenen istatistiksel Ã¶zellikleri hesapla\n",
        "# describe() metodu mean, std, min, max, Q1 (25%), Q2 (50% - median) ve Q3 (75%) deÄŸerlerini saÄŸlar\n",
        "statistical_properties = df.describe()\n",
        "display(statistical_properties)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ä°statistiksel Ã–zelliklerin HesaplanmasÄ±\n",
        "\n",
        "Bu adÄ±mda veri setindeki tÃ¼m sayÄ±sal sÃ¼tunlarÄ±n temel istatistiksel deÄŸerleri hesaplanmÄ±ÅŸtÄ±r:\n",
        "\n",
        "df.describe() fonksiyonu her Ã¶zellik iÃ§in ÅŸu bilgileri Ã¼retir:\n",
        "\n",
        "**count**: GÃ¶zlem sayÄ±sÄ±\n",
        "\n",
        "**mean**: Ortalama\n",
        "\n",
        "**std**: Standart sapma\n",
        "\n",
        "**min**: En kÃ¼Ã§Ã¼k deÄŸer\n",
        "\n",
        "**25% (Q1)**: Birinci Ã§eyreklik\n",
        "\n",
        "**50% (Q2 - median)**: Medyan\n",
        "\n",
        "**75% (Q3)**: ÃœÃ§Ã¼ncÃ¼ Ã§eyreklik\n",
        "\n",
        "**max**: En bÃ¼yÃ¼k deÄŸer\n",
        "\n",
        "Bu Ã¶zet tablo, veri setinin daÄŸÄ±lÄ±mÄ±nÄ± ve Ã¶zelliklerin genel yapÄ±sÄ±nÄ± anlamak iÃ§in kullanÄ±lÄ±r. Ã–zellikle modelden Ã¶nce veri daÄŸÄ±lÄ±mÄ±nÄ± incelemek, aykÄ±rÄ± deÄŸer ya da Ã¶lÃ§ek farklÄ±lÄ±klarÄ±nÄ± tespit etmeye yardÄ±mcÄ± olur."
      ],
      "metadata": {
        "id": "NQAoAXtLnmFo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df14e381"
      },
      "source": [
        "```\n",
        "       mean radius  mean texture  mean perimeter    mean area  \\\n",
        "count   569.000000    569.000000      569.000000   569.000000   \n",
        "mean     14.127292     19.289649       91.969033   654.889104   \n",
        "std       3.524049      4.301036       24.298981   351.914129   \n",
        "min       6.981000      9.710000       43.790000   143.500000   \n",
        "25%      11.700000     16.170000       75.170000   420.300000   \n",
        "50%      13.370000     18.840000       86.240000   551.100000   \n",
        "75%      15.790000     21.800000      104.100000   782.700000   \n",
        "max      28.110000     39.280000      188.500000  2501.000000   \n",
        "\n",
        "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
        "count       569.000000        569.000000      569.000000           569.000000   \n",
        "mean          0.096360          0.104341        0.088799             0.048919   \n",
        "std           0.014064          0.052813        0.079720             0.038803   \n",
        "min           0.052630          0.019380        0.000000             0.000000   \n",
        "25%           0.086370          0.064920        0.029560             0.020310   \n",
        "50%           0.095870          0.092630        0.061540             0.033500   \n",
        "75%           0.105300          0.130400        0.130700             0.074000   \n",
        "max           0.163400          0.345400        0.426800             0.201200   \n",
        "\n",
        "       mean symmetry  mean fractal dimension  radius error  texture error  \\\n",
        "count     569.000000              569.000000    569.000000     569.000000   \n",
        "mean        0.181162                0.062798      0.405172       1.216853   \n",
        "std         0.027414                0.007060      0.277313       0.551648   \n",
        "min         0.106000                0.049960      0.112400       0.360200   \n",
        "25%         0.161900                0.057700      0.232400       0.833900   \n",
        "50%         0.179200                0.061540      0.324200       1.108000   \n",
        "75%         0.195700                0.066120      0.478900       1.474000   \n",
        "max         0.304000                0.097440      2.873000       4.885000   \n",
        "\n",
        "       perimeter error   area error  smoothness error  compactness error  \\\n",
        "count       569.000000   569.000000        569.000000         569.000000   \n",
        "mean          2.867490   40.337079          0.007041           0.025478   \n",
        "std           2.021855   45.491006          0.003003           0.017908   \n",
        "min           0.757000    6.802000          0.001713           0.002252   \n",
        "25%           1.606000   17.850000          0.005169           0.013080   \n",
        "50%           2.287000   24.530000          0.006380           0.020450   \n",
        "75%           3.357000   45.190000          0.008146           0.032450   \n",
        "max          21.980000  542.200000          0.031130           0.135400   \n",
        "\n",
        "       concavity error  concave points error  symmetry error  \\\n",
        "count       569.000000            569.000000      569.000000   \n",
        "mean          0.031894            0.011796          0.020542   \n",
        "std           0.030186            0.006170          0.008266   \n",
        "min           0.000000            0.000000          0.007882   \n",
        "25%           0.015090            0.007638          0.015160   \n",
        "50%           0.025890            0.010930          0.018730   \n",
        "75%           0.042050            0.014710          0.023480   \n",
        "max           0.396000            0.052790          0.078950   \n",
        "\n",
        "       fractal dimension error  worst radius  worst texture  \\\n",
        "count               569.000000    569.000000     569.000000   \n",
        "mean                  0.003795     16.269190      25.677223   \n",
        "std                   0.002646      4.833242       6.146258   \n",
        "min                   0.000895      7.930000      12.020000   \n",
        "25%                   0.002248     13.010000      21.080000   \n",
        "50%                   0.003187     14.970000      25.410000   \n",
        "75%                   0.004550     18.790000      29.720000   \n",
        "max                   0.029840     36.040000      49.540000   \n",
        "\n",
        "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
        "count       569.000000   569.000000        569.000000         569.000000   \n",
        "mean         107.261213   880.583128          0.132369           0.254265   \n",
        "std           33.602542   569.356993          0.022832           0.157336   \n",
        "min           50.410000   185.200000          0.071170           0.027290   \n",
        "25%           84.110000   515.300000          0.116600           0.147200   \n",
        "50%           97.660000   686.500000          0.131300           0.211900   \n",
        "75%          125.400000  1084.000000          0.146000           0.339100   \n",
        "max          251.200000  4254.000000          0.222600           1.058000   \n",
        "\n",
        "       worst concavity  worst concave points  worst symmetry  \\\n",
        "count       569.000000            569.000000      569.000000   \n",
        "mean          0.272188            0.114606          0.290076   \n",
        "std           0.208624            0.065732          0.061867   \n",
        "min           0.000000            0.000000          0.156500   \n",
        "25%           0.114500            0.064930          0.250400   \n",
        "50%           0.226700            0.099930          0.282200   \n",
        "75%           0.382900            0.161400          0.317900   \n",
        "max           1.170000            0.291000          0.663800   \n",
        "\n",
        "       worst fractal dimension      target  \n",
        "count               569.000000  569.000000  \n",
        "mean                  0.083946    0.627417  \n",
        "std                   0.018061    0.483918  \n",
        "min                   0.055040    0.000000  \n",
        "25%                   0.071460    0.000000  \n",
        "50%                   0.080040    1.000000  \n",
        "75%                   0.092080    1.000000  \n",
        "max                   0.207500    1.000000  \n",
        "\n",
        "[8 rows x 31 columns]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cab43a2e"
      },
      "outputs": [],
      "source": [
        "# Pearson korelasyon matrisi oluÅŸturun\n",
        "correlation_matrix = df.corr(method='pearson')\n",
        "\n",
        "print(\"Pearson Korelasyon Matrisi:\")\n",
        "display(correlation_matrix.head()) # Tam matris Ã§ok bÃ¼yÃ¼k olabileceÄŸi iÃ§in ilk birkaÃ§ satÄ±rÄ± gÃ¶steriyoruz"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pearson Korelasyon Matrisi\n",
        "\n",
        "Bu adÄ±mda veri setindeki tÃ¼m deÄŸiÅŸkenler arasÄ±ndaki iliÅŸki dÃ¼zeyi incelenmiÅŸtir:\n",
        "\n",
        "df.corr(method='pearson')\n",
        "Pearson korelasyon katsayÄ±sÄ±nÄ± hesaplayarak tÃ¼m Ã¶zellikler arasÄ±ndaki doÄŸrusal iliÅŸkiyi Ã¶lÃ§er.\n",
        "\n",
        "DeÄŸer aralÄ±ÄŸÄ± -1 ile 1 arasÄ±ndadÄ±r:\n",
        "\n",
        "**1â€™e yakÄ±n** â†’ gÃ¼Ã§lÃ¼ pozitif iliÅŸki\n",
        "\n",
        "**-1â€™e yakÄ±n** â†’ gÃ¼Ã§lÃ¼ negatif iliÅŸki\n",
        "\n",
        "**0â€™a yakÄ±n** â†’ iliÅŸki yok veya Ã§ok zayÄ±f\n",
        "\n",
        "Korelasyon matrisi Ã§ok bÃ¼yÃ¼k olabileceÄŸi iÃ§in yalnÄ±zca ilk birkaÃ§ satÄ±r gÃ¶rÃ¼ntÃ¼lenmiÅŸtir.\n",
        "\n",
        "Bu analiz, Ã¶zellikle model eÄŸitiminden Ã¶nce hangi deÄŸiÅŸkenlerin birbirine Ã§ok benzediÄŸini (multicollinearity) anlamak iÃ§in kullanÄ±lÄ±r."
      ],
      "metadata": {
        "id": "BqeIe6XVoBwJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8096325f"
      },
      "source": [
        "```\n",
        "                         mean radius  mean texture  mean perimeter  mean area  \\\n",
        "mean radius                 1.000000      0.323782        0.997855   0.987357   \n",
        "mean texture                0.323782      1.000000        0.329533   0.321086   \n",
        "mean perimeter              0.997855      0.329533        1.000000   0.986507   \n",
        "mean area                   0.987357      0.321086        0.986507   1.000000   \n",
        "mean smoothness             0.170581     -0.023389        0.207<TRUNCATED original_length=8762>\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac1e9bc8"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# StandardScaler Ã¶rneÄŸi oluÅŸtur\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# X veri setini Ã¶lÃ§eklendir ve X_scaled olarak kaydet\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Ã–lÃ§eklendirilmiÅŸ verinin ilk 5 satÄ±rÄ±nÄ± gÃ¶rÃ¼ntÃ¼le\n",
        "print(\"Ã–lÃ§eklendirilmiÅŸ X_scaled verisi (ilk 5 satÄ±r):\")\n",
        "display(pd.DataFrame(X_scaled, columns=X.columns).head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ã–zellik Ã–lÃ§eklendirme (Standardization)\n",
        "\n",
        "Bu adÄ±mda modelin daha saÄŸlÄ±klÄ± Ã¶ÄŸrenebilmesi iÃ§in Ã¶zellikler standart Ã¶lÃ§eklemeye tabi tutulmuÅŸtur:\n",
        "\n",
        "**StandardScaler()**:\n",
        "Her Ã¶zelliÄŸi ortalamasÄ± 0 ve standart sapmasÄ± 1 olacak ÅŸekilde dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.\n",
        "\n",
        "Bu iÅŸlem, Ã¶zellikle mesafeye duyarlÄ± algoritmalar (Ã¶r. KNN, SVM) veya gradyan tabanlÄ± yÃ¶ntemler iÃ§in Ã¶nemlidir.\n",
        "\n",
        "**scaler.fit_transform(X)**:\n",
        "\n",
        "**fit kÄ±smÄ±**: Verinin ortalama ve standart sapmasÄ±nÄ± Ã¶ÄŸrenir\n",
        "\n",
        "**transform kÄ±smÄ±**: Veriyi bu ortalama ve standart sapmaya gÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r\n",
        "\n",
        "DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ veri X_scaled olarak kaydedilir ve ilk 5 satÄ±r gÃ¶rÃ¼ntÃ¼lenir.\n",
        "\n",
        "Standardizasyon, farklÄ± Ã¶lÃ§eklerdeki Ã¶zelliklerin model eÄŸitiminde eÅŸit aÄŸÄ±rlÄ±kta olmasÄ±nÄ± saÄŸlar."
      ],
      "metadata": {
        "id": "UkW72wi1oizS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38f5951c"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Ä°lk BÃ¶lme: EÄŸitim seti (%70) ve GeÃ§ici (DoÄŸrulama + Test) seti (%30)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Ä°kinci BÃ¶lme: GeÃ§ici setten DoÄŸrulama (%10) ve Test (%20) setlerinin ayrÄ±lmasÄ±\n",
        "# X_temp'in %10'unu almak iÃ§in (ki bu da orijinal verinin %10'una tekabÃ¼l eder),\n",
        "# X_temp'in 1/3'Ã¼nÃ¼ doÄŸrulama, 2/3'Ã¼nÃ¼ test olarak ayÄ±rmalÄ±yÄ±z.\n",
        "# Yani test_size = 0.20 / 0.30 = 2/3\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=(0.20 / 0.30), random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "# OluÅŸan setlerin boyutlarÄ±nÄ± kontrol et\n",
        "print(f\"EÄŸitim seti boyutu: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print(f\"DoÄŸrulama seti boyutu: X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
        "print(f\"Test seti boyutu: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "\n",
        "# Orijinal veri setinin boyutunu kontrol et\n",
        "print(f\"Orijinal veri seti boyutu: {X_scaled.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9037d8e3"
      },
      "source": [
        "EÄŸitim seti boyutu: X_train: (398, 30), y_train: (398,)\n",
        "DoÄŸrulama seti boyutu: X_val: (56, 30), y_val: (56,)\n",
        "Test seti boyutu: X_test: (115, 30), y_test: (115,)\n",
        "Orijinal veri seti boyutu: (569, 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Veri Setinin EÄŸitim, DoÄŸrulama ve Test Setlerine BÃ¶lÃ¼nmesi\n",
        "\n",
        "Bu adÄ±mda Ã¶lÃ§eklendirilmiÅŸ veri seti, modelin eÄŸitim ve deÄŸerlendirmesi iÃ§in Ã¼Ã§ alt kÃ¼meye ayrÄ±lmÄ±ÅŸtÄ±r:\n",
        "\n",
        "1. **EÄŸitim ve GeÃ§ici Setin AyrÄ±lmasÄ±**\n",
        "\n",
        "train_test_split ile veri setinin %70â€™i eÄŸitim iÃ§in, %30â€™u geÃ§ici set iÃ§in ayrÄ±lÄ±r.\n",
        "\n",
        "stratify=y parametresi, sÄ±nÄ±f oranlarÄ±nÄ±n eÄŸitim ve geÃ§ici setlerde de korunmasÄ±nÄ± saÄŸlar.\n",
        "\n",
        "random_state=42 ile bÃ¶lme iÅŸlemi tekrarlanabilir hÃ¢le getirilir.\n",
        "\n",
        "2. **DoÄŸrulama ve Test Setine AyrÄ±lmasÄ±**\n",
        "\n",
        "GeÃ§ici setten:\n",
        "\n",
        "%1/3â€™Ã¼ (orijinal veri setinin %10â€™u) doÄŸrulama (validation) iÃ§in\n",
        "\n",
        "%2/3â€™Ã¼ (orijinal veri setinin %20â€™si) test iÃ§in ayrÄ±lÄ±r.\n",
        "\n",
        "Bu sayede model eÄŸitim sÄ±rasÄ±nda doÄŸrulama seti ile ayarlamalar yapabilir, test seti ile baÄŸÄ±msÄ±z performans Ã¶lÃ§Ã¼mÃ¼ yapÄ±labilir.\n",
        "\n",
        "3. **Boyut KontrolÃ¼**\n",
        "\n",
        "EÄŸitim, doÄŸrulama ve test setlerinin boyutlarÄ± shape ile kontrol edilir.\n",
        "\n",
        "AyrÄ±ca, toplam boyutlarÄ±n orijinal veri seti ile uyumlu olduÄŸu doÄŸrulanÄ±r.\n",
        "\n",
        "Bu adÄ±m, modelin genelleme yeteneÄŸini doÄŸru ÅŸekilde deÄŸerlendirmek iÃ§in kritik Ã¶neme sahiptir."
      ],
      "metadata": {
        "id": "lWhJRGSSp7Do"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GX8M9Ch8BmN_"
      },
      "outputs": [],
      "source": [
        "#2.2 AykÄ±rÄ± DeÄŸer (Outlier) Analizi\n",
        "\n",
        "# IQR yÃ¶ntemi ile aykÄ±rÄ± deÄŸer analizi\n",
        "Q1 = df.quantile(0.25)\n",
        "Q3 = df.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Her sÃ¼tunda aykÄ±rÄ± deÄŸerleri say\n",
        "outliers = ((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).sum()\n",
        "print(\"Her sÃ¼tundaki aykÄ±rÄ± deÄŸer sayÄ±sÄ±:\\n\", outliers)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AykÄ±rÄ± DeÄŸer (Outlier) Analizi**\n",
        "\n",
        "Bu adÄ±mda veri setindeki aykÄ±rÄ± deÄŸerler IQR (Interquartile Range) yÃ¶ntemi ile tespit edilmiÅŸtir:\n",
        "\n",
        "Q1 ve Q3: Her sÃ¼tunun 1. ve 3. Ã§eyreklik deÄŸerleri hesaplanÄ±r.\n",
        "\n",
        "IQR = Q3 - Q1: Ã‡eyreklikler arasÄ± mesafe (Interquartile Range) bulunur.\n",
        "\n",
        "**AykÄ±rÄ± deÄŸer kriteri**:\n",
        "\n",
        "**Alt sÄ±nÄ±r**: Q1 - 1.5 Ã— IQR\n",
        "\n",
        "**Ãœst sÄ±nÄ±r**: Q3 + 1.5 Ã— IQR\n",
        "\n",
        "Bu sÄ±nÄ±rlarÄ±n dÄ±ÅŸÄ±nda kalan deÄŸerler aykÄ±rÄ± olarak kabul edilir.\n",
        "\n",
        "Her sÃ¼tunda aykÄ±rÄ± deÄŸerlerin sayÄ±sÄ± hesaplanÄ±r ve ekrana yazdÄ±rÄ±lÄ±r.\n",
        "\n",
        "AykÄ±rÄ± deÄŸer analizi, modelin eÄŸitimi sÄ±rasÄ±nda ekstrem deÄŸerlerin etkisini anlamak ve gerekirse Ã¶nlem almak iÃ§in Ã¶nemlidir."
      ],
      "metadata": {
        "id": "JSOZ98aIqkX9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4956cc6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "\n",
        "#Z Score Analizi\n",
        "\n",
        "# Sadece sayÄ±sal sÃ¼tunlarÄ± seÃ§ (target sÃ¼tununu hariÃ§ tuttuÄŸumuz X DataFrame'i zaten sayÄ±sal)\n",
        "z_scores = np.abs(zscore(X))\n",
        "\n",
        "# EÅŸik deÄŸeri belirle (genellikle 3 veya 2.5 kullanÄ±lÄ±r)\n",
        "threshold = 3\n",
        "\n",
        "# Her sÃ¼tunda eÅŸik deÄŸerini aÅŸan aykÄ±rÄ± deÄŸerleri bul\n",
        "outlier_counts_zscore = (z_scores > threshold).sum(axis=0)\n",
        "\n",
        "print(\"Z-Score ile her sÃ¼tundaki aykÄ±rÄ± deÄŸer sayÄ±sÄ± (eÅŸik: 3):\")\n",
        "print(outlier_counts_zscore)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Z-Score ile AykÄ±rÄ± DeÄŸer Analizi\n",
        "\n",
        "Bu adÄ±mda veri setindeki aykÄ±rÄ± deÄŸerler Z-Score yÃ¶ntemi ile tespit edilmiÅŸtir:\n",
        "\n",
        "zscore(X): Her bir Ã¶zelliÄŸin standart skorunu (Z-Score) hesaplar:\n",
        "\n",
        "\n",
        "\tâ€‹z = (x-Î¼ )/Ïƒ\n",
        "\n",
        "\n",
        "**x** : veri noktasÄ±\n",
        "\n",
        "\n",
        "**Î¼** : sÃ¼tunun ortalamasÄ±\n",
        "\n",
        "\n",
        "**Ïƒ** : sÃ¼tunun standart sapmasÄ±\n",
        "\n",
        "**np.abs(z_scores)**: Pozitif ve negatif uÃ§ deÄŸerleri birlikte deÄŸerlendirmek iÃ§in mutlak deÄŸer alÄ±nÄ±r.\n",
        "\n",
        "**Threshold (eÅŸik deÄŸeri)**: Genellikle 3 veya 2.5 olarak seÃ§ilir; Z-Scoreâ€™u bu deÄŸeri aÅŸan noktalar aykÄ±rÄ± kabul edilir.\n",
        "\n",
        "**(z_scores > threshold).sum(axis=0)**: Her sÃ¼tundaki aykÄ±rÄ± deÄŸerlerin sayÄ±sÄ±nÄ± hesaplar.\n",
        "\n",
        "Z-Score yÃ¶ntemi, IQRâ€™a ek olarak ekstrem deÄŸerleri tespit etmek iÃ§in yaygÄ±n kullanÄ±lÄ±r ve Ã¶zellikle normal daÄŸÄ±lÄ±ma yakÄ±n verilerde etkilidir."
      ],
      "metadata": {
        "id": "OXZVmA84rcmk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3032fad9"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "#Boxplot Analizi\n",
        "\n",
        "# Ã–zellik sayÄ±sÄ±nÄ± al\n",
        "num_features = X.shape[1]\n",
        "\n",
        "# Subplot'lar iÃ§in uygun bir Ä±zgara boyutu belirle\n",
        "n_cols = 5 # Her satÄ±rda kaÃ§ sÃ¼tun olacaÄŸÄ±nÄ± belirle\n",
        "n_rows = (num_features + n_cols - 1) // n_cols # Gerekli satÄ±r sayÄ±sÄ±nÄ± hesapla\n",
        "\n",
        "plt.figure(figsize=(n_cols * 4, n_rows * 3))\n",
        "\n",
        "for i, column in enumerate(X.columns):\n",
        "    plt.subplot(n_rows, n_cols, i + 1)\n",
        "    sns.boxplot(y=X[column])\n",
        "    plt.title(column, fontsize=10)\n",
        "    plt.ylabel('') # Y ekseni etiketlerini kaldÄ±rarak daha dÃ¼zenli bir gÃ¶rÃ¼nÃ¼m saÄŸlar\n",
        "    plt.xlabel('') # X ekseni etiketlerini kaldÄ±r\n",
        "    plt.tick_params(axis='y', labelsize=8) # Y ekseni etiketlerinin boyutunu kÃ¼Ã§Ã¼lt\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Boxplot ile AykÄ±rÄ± DeÄŸer GÃ¶rselleÅŸtirme\n",
        "\n",
        "Bu adÄ±mda veri setindeki aykÄ±rÄ± deÄŸerler gÃ¶rsel olarak incelenmiÅŸtir:\n",
        "\n",
        "**Boxplot (kutu grafiÄŸi)**: Her Ã¶zelliÄŸin daÄŸÄ±lÄ±mÄ±nÄ±, medyanÄ±nÄ±, Ã§eyrekliklerini ve aykÄ±rÄ± deÄŸerlerini gÃ¶rmemizi saÄŸlar.\n",
        "\n",
        "**Kutu**: Q1 ve Q3 arasÄ±ndaki deÄŸerleri temsil eder\n",
        "\n",
        "**Orta Ã§izgi**: Medyan (Q2)\n",
        "\n",
        "**â€œWhiskerâ€ uÃ§larÄ±**: Alt ve Ã¼st sÄ±nÄ±rlar\n",
        "\n",
        "**Noktalar**: AykÄ±rÄ± deÄŸerler\n",
        "\n",
        "Ã‡ok sayÄ±da Ã¶zellik olduÄŸu iÃ§in subplotâ€™lar kullanÄ±lmÄ±ÅŸ ve her satÄ±rda 5 sÃ¼tun olacak ÅŸekilde Ä±zgara oluÅŸturulmuÅŸtur.\n",
        "\n",
        "plt.tight_layout() ile grafikler arasÄ±ndaki boÅŸluklar dÃ¼zenlenir, bÃ¶ylece tÃ¼m boxplotâ€™lar okunabilir olur.\n",
        "\n",
        "Boxplot analizi, hem IQR hem de Z-Score yÃ¶ntemleri ile tespit edilen aykÄ±rÄ± deÄŸerlerin gÃ¶rselleÅŸtirilmesini saÄŸlar.\n",
        "\n",
        "Bu gÃ¶rselleÅŸtirme, veri setindeki ekstrem deÄŸerleri hÄ±zlÄ±ca tanÄ±mlamak ve gerekirse iÅŸlem yapmak iÃ§in kullanÄ±lÄ±r."
      ],
      "metadata": {
        "id": "dxHz6FOfsPTm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f6671c9"
      },
      "source": [
        "### 2.3 Veri Tipi ve DaÄŸÄ±lÄ±m Ä°ncelemesi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cedfb4ef"
      },
      "outputs": [],
      "source": [
        "# SayÄ±sal ve kategorik deÄŸiÅŸken sayÄ±larÄ±nÄ± raporlama\n",
        "numerical_cols = df.select_dtypes(include=['number']).columns\n",
        "categorical_cols = df.select_dtypes(exclude=['number']).columns\n",
        "\n",
        "print(f\"SayÄ±sal DeÄŸiÅŸken SayÄ±sÄ±: {len(numerical_cols)}\")\n",
        "print(f\"Kategorik DeÄŸiÅŸken SayÄ±sÄ±: {len(categorical_cols)}\")\n",
        "\n",
        "print(\"\\nSayÄ±sal SÃ¼tunlar:\")\n",
        "print(list(numerical_cols))\n",
        "\n",
        "print(\"\\nKategorik SÃ¼tunlar:\")\n",
        "print(list(categorical_cols))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SayÄ±sal ve Kategorik DeÄŸiÅŸkenlerin Ä°ncelenmesi\n",
        "\n",
        "Bu adÄ±mda veri setindeki deÄŸiÅŸkenlerin tÃ¼rleri analiz edilmiÅŸtir:\n",
        "\n",
        "**SayÄ±sal deÄŸiÅŸkenler (numerical_cols)**:\n",
        "\n",
        "select_dtypes(include=['number']) ile sayÄ±sal tipteki sÃ¼tunlar seÃ§ilir.\n",
        "\n",
        "Bu sÃ¼tunlar genellikle modelde doÄŸrudan kullanÄ±labilir ve sayÄ±sal iÅŸlemler (Ã¶lÃ§ekleme, istatistiksel analiz) uygulanabilir.\n",
        "\n",
        "**Kategorik deÄŸiÅŸkenler (categorical_cols)**:\n",
        "\n",
        "select_dtypes(exclude=['number']) ile sayÄ±sal olmayan sÃ¼tunlar seÃ§ilir.\n",
        "\n",
        "Bu sÃ¼tunlar genellikle etiketleme veya one-hot encoding gibi Ã¶n iÅŸleme adÄ±mlarÄ±na ihtiyaÃ§ duyar.\n",
        "\n",
        "**SonuÃ§ olarak**:\n",
        "\n",
        "SayÄ±sal ve kategorik sÃ¼tunlarÄ±n sayÄ±sÄ± ve isimleri ekrana yazdÄ±rÄ±lÄ±r.\n",
        "\n",
        "Bu adÄ±m, veri setinin yapÄ±sÄ±nÄ± anlamak ve model Ã¶ncesi gerekli iÅŸlemleri planlamak iÃ§in Ã¶nemlidir.\n",
        "\n",
        "Breast Cancer veri setinde tÃ¼m sÃ¼tunlar sayÄ±sal olduÄŸundan kategorik sÃ¼tun bulunmamaktadÄ±r."
      ],
      "metadata": {
        "id": "JmOVIcJAsiqi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d908c55d"
      },
      "outputs": [],
      "source": [
        "# SÃ¼tunlarÄ±n dtype bilgilerini gÃ¶sterme\n",
        "print(\"\\nSÃ¼tunlarÄ±n Veri Tipleri (dtype bilgileri):\\n\")\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SÃ¼tunlarÄ±n Veri Tipleri (dtype) Ä°ncelemesi\n",
        "\n",
        "Bu adÄ±mda veri setindeki her sÃ¼tunun veri tipi (dtype) ve temel bilgileri incelenmiÅŸtir:\n",
        "\n",
        "**df.info() fonksiyonu ile**:\n",
        "\n",
        "SÃ¼tun isimleri\n",
        "\n",
        "SÃ¼tunlardaki gÃ¶zlem sayÄ±sÄ±\n",
        "\n",
        "Veri tipleri (int, float, object vb.)\n",
        "\n",
        "Bellek kullanÄ±mÄ±\n",
        "\n",
        "gibi bilgiler ekrana yazdÄ±rÄ±lÄ±r.\n",
        "\n",
        "**AmaÃ§**:\n",
        "\n",
        "Hangi sÃ¼tunlarÄ±n sayÄ±sal veya kategorik olduÄŸunu doÄŸrulamak\n",
        "\n",
        "Eksik deÄŸer durumunu hÄ±zlÄ±ca gÃ¶rmek\n",
        "\n",
        "Bellek kullanÄ±mÄ± ve veri tipi uyumsuzluklarÄ±nÄ± kontrol etmek\n",
        "\n",
        "Bu adÄ±m, veri setinin genel yapÄ±sÄ±nÄ± anlamak ve Ã¶n iÅŸleme ihtiyaÃ§larÄ±nÄ± belirlemek iÃ§in kritik bir adÄ±mdÄ±r."
      ],
      "metadata": {
        "id": "Ed2iDjdMs4hK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLtQP3mYJAbg"
      },
      "source": [
        "## 3. KeÅŸifsel Veri Analizi (EDA)\n",
        "### 3.1 Ä°statistiksel Ã–zellikler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nu-qP73jI_h1"
      },
      "outputs": [],
      "source": [
        "# Her sÃ¼tun iÃ§in istenen istatistiksel Ã¶zellikleri hesapla\n",
        "# describe() metodu mean, std, min, max, Q1 (25%), Q2 (50% - median) ve Q3 (75%) deÄŸerlerini saÄŸlar\n",
        "statistical_properties = df.describe()\n",
        "display(statistical_properties)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ä°statistiksel Ã–zelliklerin HesaplanmasÄ±\n",
        "\n",
        "Bu adÄ±mda veri setindeki tÃ¼m sayÄ±sal sÃ¼tunlarÄ±n temel istatistiksel deÄŸerleri hesaplanmÄ±ÅŸtÄ±r:\n",
        "\n",
        "**df.describe() fonksiyonu her Ã¶zellik iÃ§in ÅŸu bilgileri Ã¼retir**:\n",
        "\n",
        "**count**: GÃ¶zlem sayÄ±sÄ±\n",
        "\n",
        "**mean**: Ortalama\n",
        "\n",
        "**std**: Standart sapma\n",
        "\n",
        "**min**: En kÃ¼Ã§Ã¼k deÄŸer\n",
        "\n",
        "**25% (Q1)**: Birinci Ã§eyreklik\n",
        "\n",
        "**50% (Q2 - median)**: Medyan\n",
        "\n",
        "**75% (Q3)**: ÃœÃ§Ã¼ncÃ¼ Ã§eyreklik\n",
        "\n",
        "**max**: En bÃ¼yÃ¼k deÄŸer\n",
        "\n",
        "Bu Ã¶zet tablo, veri setinin daÄŸÄ±lÄ±mÄ±nÄ± ve Ã¶zelliklerin genel yapÄ±sÄ±nÄ± anlamak iÃ§in kullanÄ±lÄ±r. Ã–zellikle model Ã¶ncesi veri daÄŸÄ±lÄ±mÄ±nÄ± ve potansiyel aykÄ±rÄ± deÄŸerleri gÃ¶zlemlemek iÃ§in faydalÄ±dÄ±r."
      ],
      "metadata": {
        "id": "1QKc6hs1tiWj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd69c3e9"
      },
      "source": [
        "### 3.2 Korelasyon Matrisi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e19f57d7"
      },
      "outputs": [],
      "source": [
        "# Pearson korelasyon matrisi oluÅŸturun\n",
        "correlation_matrix = df.corr(method='pearson')\n",
        "\n",
        "print(\"Pearson Korelasyon Matrisi:\")\n",
        "display(correlation_matrix.head()) # Tam matris Ã§ok bÃ¼yÃ¼k olabileceÄŸi iÃ§in ilk birkaÃ§ satÄ±rÄ± gÃ¶steriyoruz"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pearson Korelasyon Matrisi\n",
        "\n",
        "Bu adÄ±mda veri setindeki tÃ¼m deÄŸiÅŸkenler arasÄ±ndaki doÄŸrusal iliÅŸkiler Pearson korelasyon katsayÄ±sÄ± ile incelenmiÅŸtir:\n",
        "\n",
        "**df.corr(method='pearson')**:\n",
        "\n",
        "Her sÃ¼tunun diÄŸer sÃ¼tunlarla olan doÄŸrusal iliÅŸkisini Ã¶lÃ§er.\n",
        "\n",
        "**DeÄŸer aralÄ±ÄŸÄ±**: -1 ile 1\n",
        "\n",
        "**1â€™e yakÄ±n** â†’ gÃ¼Ã§lÃ¼ pozitif iliÅŸki\n",
        "\n",
        "**-1â€™e yakÄ±n** â†’ gÃ¼Ã§lÃ¼ negatif iliÅŸki\n",
        "\n",
        "**0â€™a yakÄ±n** â†’ iliÅŸki yok veya Ã§ok zayÄ±f\n",
        "\n",
        "Korelasyon matrisi Ã§ok bÃ¼yÃ¼k olabileceÄŸi iÃ§in yalnÄ±zca ilk birkaÃ§ satÄ±r gÃ¶rÃ¼ntÃ¼lenmiÅŸtir.\n",
        "\n",
        "Bu analiz, Ã¶zellikle model Ã¶ncesi Ã§ok yÃ¼ksek korelasyonlu deÄŸiÅŸkenlerin olup olmadÄ±ÄŸÄ±nÄ± anlamak ve multicollinearity riskini deÄŸerlendirmek iÃ§in kullanÄ±lÄ±r."
      ],
      "metadata": {
        "id": "J9auHFdEuQ2a"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc15b7db"
      },
      "source": [
        "#### Heatmap ile Korelasyon Matrisinin GÃ¶rselleÅŸtirilmesi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "792a0c9f"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "# Pearson korelasyon matrisi oluÅŸturun (daha Ã¶nce oluÅŸturulduysa tekrar Ã§alÄ±ÅŸtÄ±rÄ±labilir)\n",
        "correlation_matrix = df.corr(method='pearson')\n",
        "\n",
        "plt.figure(figsize=(20, 18)) # GÃ¶rselleÅŸtirme boyutu\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
        "plt.title('Pearson Korelasyon Matrisi Heatmap', fontsize=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**df.corr()**: Veri setindeki tÃ¼m sayÄ±sal sÃ¼tunlar arasÄ±ndaki korelasyon katsayÄ±larÄ±nÄ± hesaplar.\n",
        "\n",
        "Pearson yÃ¶ntemi, deÄŸiÅŸkenler arasÄ±ndaki doÄŸrusal iliÅŸkiyi Ã¶lÃ§er.\n",
        "\n",
        "Heatmap, iliÅŸkilerin kuvvetini renklerle gÃ¶sterir:\n",
        "\n",
        "ğŸ”´ KÄ±rmÄ±zÄ±: GÃ¼Ã§lÃ¼ pozitif korelasyon\n",
        "\n",
        "ğŸ”µ Mavi: GÃ¼Ã§lÃ¼ negatif korelasyon\n",
        "\n",
        "âšª Beyaz / aÃ§Ä±k tonlar: ZayÄ±f ya da iliÅŸkisiz deÄŸiÅŸkenler\n",
        "\n",
        "Bu gÃ¶rselleÅŸtirme, model eÄŸitiminde Ã¶nemli deÄŸiÅŸkenlerin belirlenmesi, Ã§oklu doÄŸrusal baÄŸlantÄ±larÄ±n incelenmesi ve veri setinin yapÄ±sÄ±nÄ±n analiz edilmesi iÃ§in oldukÃ§a yararlÄ±dÄ±r."
      ],
      "metadata": {
        "id": "bcmRcexWuxzt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fb221f9"
      },
      "outputs": [],
      "source": [
        "# Korelasyon matrisinden Ã¼st Ã¼Ã§geni alarak tekrar eden Ã§iftleri ve kendisiyle olan korelasyonu Ã§Ä±karÄ±yoruz\n",
        "corr_pairs = correlation_matrix.unstack()\n",
        "sorted_pairs = corr_pairs.sort_values(kind=\"quicksort\", ascending=False)\n",
        "\n",
        "# Kendisiyle olan korelasyonlarÄ± (1.0) ve tekrar eden Ã§iftleri eleyerek en yÃ¼ksek 3 korelasyonu bulma\n",
        "high_corr_pairs = sorted_pairs[sorted_pairs != 1.0]\n",
        "\n",
        "# Ä°lk 6 Ã§ifti al (Ã§Ã¼nkÃ¼ A-B ve B-A aynÄ± korelasyonu temsil eder, 3 Ã§ift iÃ§in 6 sonuÃ§ olacaktÄ±r)\n",
        "top_3_correlated_pairs = high_corr_pairs[::2].head(3)\n",
        "\n",
        "print(\"En yÃ¼ksek korelasyonlu 3 Ã§ift:\")\n",
        "display(top_3_correlated_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**unstack()**\n",
        "Korelasyon matrisini uzun formata Ã§evirir. BÃ¶ylece her hÃ¼cre (deÄŸiÅŸken1, deÄŸiÅŸken2) ÅŸeklinde bir Ã§ift oluÅŸturur.\n",
        "\n",
        "Tekrar eden Ã§iftlerin atÄ±lmasÄ±\n",
        "Korelasyon matrisi simetriktir; Ã¶rneÄŸin:\n",
        "\n",
        "**mean radius** â€“ mean area\n",
        "\n",
        "**mean area** â€“ mean radius\n",
        "aynÄ± korelasyon deÄŸerini temsil eder.\n",
        "Bu nedenle 2'ÅŸer atlayarak benzersiz Ã§iftler elde edilir.\n",
        "\n",
        "Kendisiyle olan korelasyonlarÄ±n Ã§Ä±karÄ±lmasÄ±\n",
        "\n",
        "Her deÄŸiÅŸken kendisiyle 1.0 korelasyona sahiptir; anlamlÄ± bilgi saÄŸlamadÄ±ÄŸÄ± iÃ§in listeden Ã§Ä±karÄ±lÄ±r.\n",
        "\n",
        "SonuÃ§\n",
        "Kod, veri setindeki deÄŸiÅŸkenler arasÄ±ndan en gÃ¼Ã§lÃ¼ doÄŸrusal iliÅŸkiye sahip 3 Ã§ifti bulur."
      ],
      "metadata": {
        "id": "mMncFhQtvH-a"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb859043"
      },
      "source": [
        "### Boxplot'lar ile Hedef DeÄŸiÅŸken ArasÄ±ndaki Ä°liÅŸkiyi Ä°nceleme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79419319"
      },
      "outputs": [],
      "source": [
        "# Hedef deÄŸiÅŸken (target) ile iliÅŸkiyi incelemek iÃ§in boxplot'lar Ã§iziyoruz\n",
        "# X (Ã¶zellikler) ve y (hedef) DataFrame'lerini tekrar birleÅŸtiriyoruz\n",
        "df_combined = pd.concat([X, y], axis=1)\n",
        "\n",
        "num_features = X.shape[1]\n",
        "n_cols = 5 # Her satÄ±rda kaÃ§ sÃ¼tun olacaÄŸÄ±nÄ± belirle\n",
        "n_rows = (num_features + n_cols - 1) // n_cols # Gerekli satÄ±r sayÄ±sÄ±nÄ± hesapla\n",
        "\n",
        "plt.figure(figsize=(n_cols * 4, n_rows * 3 * 1.2)) # Daha fazla yer aÃ§mak iÃ§in yÃ¼kseklik artÄ±rÄ±ldÄ±\n",
        "\n",
        "for i, column in enumerate(X.columns):\n",
        "    plt.subplot(n_rows, n_cols, i + 1)\n",
        "    sns.boxplot(x='target', y=column, data=df_combined, palette='viridis')\n",
        "    plt.title(column, fontsize=10)\n",
        "    plt.xlabel('Target (0: Malign, 1: Benign)', fontsize=8) # Hedef deÄŸiÅŸkenin ne anlama geldiÄŸi belirtildi\n",
        "    plt.ylabel('')\n",
        "    plt.tick_params(axis='y', labelsize=8)\n",
        "    plt.tick_params(axis='x', labelsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hedef DeÄŸiÅŸken (Target) ile Ã–zellikler ArasÄ±ndaki Ä°liÅŸkinin Boxplot Analizi\n",
        "\n",
        "Bu bÃ¶lÃ¼mde, her bir baÄŸÄ±msÄ±z deÄŸiÅŸkenin (Ã¶zellik) hedef deÄŸiÅŸkenle (target: 0 = malign, 1 = benign) olan daÄŸÄ±lÄ±mÄ±nÄ± incelemek iÃ§in boxplot grafikleri oluÅŸturulmuÅŸtur.\n",
        "\n",
        "Boxplot'lar, hem ortanca, hem deÄŸiÅŸken daÄŸÄ±lÄ±mÄ±, hem de aykÄ±rÄ± deÄŸerleri gÃ¶rmemizi saÄŸlar; bu nedenle sÄ±nÄ±flar arasÄ± farklarÄ±n analizinde oldukÃ§a bilgilendiricidir.\n",
        "\n",
        "**df_combined = pd.concat([X, y], axis=1)**\n",
        "\n",
        "Ã–zellikler (X) ile hedef deÄŸiÅŸken (y), grafiklerde birlikte kullanÄ±labilmeleri iÃ§in tek bir DataFrameâ€™de birleÅŸtirilmiÅŸtir.\n",
        "\n",
        "**n_rows ve n_cols**\n",
        "\n",
        "TÃ¼m deÄŸiÅŸkenler iÃ§in boxplot oluÅŸturulacaÄŸÄ± iÃ§in subplot dÃ¼zeni dinamik olarak hesaplanmÄ±ÅŸtÄ±r.\n",
        "\n",
        "**sns.boxplot(x='target', y=column)**\n",
        "\n",
        "Her bir Ã¶zelliÄŸin, malign (0) ve benign (1) sÄ±nÄ±flarÄ± iÃ§in daÄŸÄ±lÄ±mÄ± ayrÄ± ayrÄ± gÃ¶sterilir.\n",
        "\n",
        "**palette='viridis'**\n",
        "\n",
        "GÃ¶rsel uyumluluk iÃ§in renk paleti kullanÄ±lmÄ±ÅŸtÄ±r.\n",
        "\n",
        "**plt.tight_layout()**\n",
        "\n",
        "Grafiklerin Ã¼st Ã¼ste binmemesi iÃ§in yerleÅŸim otomatik olarak dÃ¼zenlenmiÅŸtir."
      ],
      "metadata": {
        "id": "c6cAZpGFvmEw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75cdc2ba"
      },
      "source": [
        "## 4. Veri Ã–lÃ§eklendirme (Scaling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4f775e78"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# StandardScaler Ã¶rneÄŸi oluÅŸtur\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# X veri setini Ã¶lÃ§eklendir ve X_scaled olarak kaydet\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Ã–lÃ§eklendirilmiÅŸ verinin ilk 5 satÄ±rÄ±nÄ± gÃ¶rÃ¼ntÃ¼le\n",
        "print(\"Ã–lÃ§eklendirilmiÅŸ X_scaled verisi (ilk 5 satÄ±r):\")\n",
        "display(pd.DataFrame(X_scaled, columns=X.columns).head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Her bir deÄŸiÅŸken ortalamasÄ± 0, standart sapmasÄ± 1 olacak ÅŸekilde normalize edilir.\n",
        "\n",
        "**StandardScaler()**\n",
        "\n",
        "Veri seti Ã¼zerindeki her sÃ¼tunun ortalamasÄ±nÄ± (mean) ve standart sapmasÄ±nÄ± (std) hesaplar.\n",
        "\n",
        "**fit_transform(X)**\n",
        "\n",
        "fit() â†’ Xâ€™in istatistiklerini (Âµ ve Ïƒ) Ã¶ÄŸrenir\n",
        "transform() â†’ tÃ¼m sÃ¼tunlarÄ± standart Ã¶lÃ§eÄŸe dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r\n",
        "\n",
        "**X_scaled**\n",
        "\n",
        "ArtÄ±k tÃ¼m Ã¶zellikler aynÄ± Ã¶lÃ§ekte bulunduÄŸu iÃ§in modeller daha stabil ve doÄŸru Ã§alÄ±ÅŸacaktÄ±r.\n",
        "\n",
        "Son satÄ±rda Ã¶lÃ§eklendirilmiÅŸ verinin ilk 5 Ã¶rneÄŸi gÃ¶rÃ¼ntÃ¼lenerek dÃ¶nÃ¼ÅŸÃ¼m doÄŸrulanÄ±r."
      ],
      "metadata": {
        "id": "U0SGG7wywFjC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMksAksLO51G"
      },
      "source": [
        "## 5. Veri Setinin BÃ¶lÃ¼nmesi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_54ShH0O6UH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Ä°lk BÃ¶lme: EÄŸitim seti (%70) ve GeÃ§ici (DoÄŸrulama + Test) seti (%30)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Ä°kinci BÃ¶lme: GeÃ§ici setten DoÄŸrulama (%10) ve Test (%20) setlerinin ayrÄ±lmasÄ±\n",
        "# X_temp'in %10'unu almak iÃ§in (ki bu da orijinal verinin %10'una tekabÃ¼l eder),\n",
        "# X_temp'in 1/3'Ã¼nÃ¼ doÄŸrulama, 2/3'Ã¼nÃ¼ test olarak ayÄ±rmalÄ±yÄ±z.\n",
        "# Yani test_size = 0.20 / 0.30 = 2/3\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=(0.20 / 0.30), random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "# OluÅŸan setlerin boyutlarÄ±nÄ± kontrol et\n",
        "print(f\"EÄŸitim seti boyutu: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print(f\"DoÄŸrulama seti boyutu: X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
        "print(f\"Test seti boyutu: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "\n",
        "# Orijinal veri setinin boyutunu kontrol et\n",
        "print(f\"Orijinal veri seti boyutu: {X_scaled.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Makine Ã¶ÄŸrenimi modellerinin performansÄ±nÄ± doÄŸru deÄŸerlendirebilmek iÃ§in veri setini genellikle Ã¼Ã§ parÃ§aya ayÄ±rÄ±rÄ±z:\n",
        "\n",
        "**EÄŸitim Seti (Train)**: Modelin Ã¶ÄŸrenmesi iÃ§in kullanÄ±lÄ±r\n",
        "\n",
        "**DoÄŸrulama Seti (Validation)**: Modelin hiperparametre ayarlarÄ±nda ve erken durdurmada kullanÄ±lÄ±r\n",
        "\n",
        "**Test Seti (Test)**: Modelin nihai baÅŸarÄ±sÄ±nÄ± Ã¶lÃ§mek iÃ§in ayrÄ±lÄ±r\n",
        "\n",
        "Bu projede veri seti ÅŸu oranlarda bÃ¶lÃ¼nmÃ¼ÅŸtÃ¼r:\n",
        "\n",
        "**%70** â†’ EÄŸitim\n",
        "\n",
        "**%10** â†’ DoÄŸrulama\n",
        "\n",
        "**%20** â†’ Test\n",
        "\n",
        "---\n",
        "\n",
        "train_test_split() fonksiyonu kullanÄ±larak veri iki aÅŸamada bÃ¶lÃ¼nmÃ¼ÅŸtÃ¼r.\n",
        "\n",
        "**Ä°lk aÅŸamada**:\n",
        "\n",
        "%70 eÄŸitim\n",
        "\n",
        "%30 geÃ§ici (â€œvalidation + testâ€) seti oluÅŸturulur.\n",
        "\n",
        "**Ä°kinci aÅŸamada geÃ§ici set tekrar bÃ¶lÃ¼nerek**:\n",
        "\n",
        "1/3 doÄŸrulama (validation)\n",
        "\n",
        "2/3 test\n",
        "olacak ÅŸekilde ayrÄ±lÄ±r.\n",
        "\n",
        "**stratify=y**â†’ Veri setindeki sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ±n tÃ¼m alt kÃ¼melerde aynÄ± kalmasÄ±nÄ± saÄŸlar.\n",
        "(Bu Ã¶zellikle dengesiz veri setlerinde Ã§ok Ã¶nemlidir.)\n",
        "\n",
        "Son olarak tÃ¼m setlerin boyutlarÄ± ekrana yazdÄ±rÄ±larak bÃ¶lme iÅŸlemi doÄŸrulanÄ±r."
      ],
      "metadata": {
        "id": "QXgGnXKcwadC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "275fcefe"
      },
      "source": [
        "## 6. FarklÄ± MLP Modellerinin KurulmasÄ±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce54ad3c"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Model 1 â€“ Basit\n",
        "# hidden_layer_sizes=(16,)\n",
        "# activation=\"relu\"\n",
        "# learning_rate_init=0.001\n",
        "mlp_model_1 = MLPClassifier(hidden_layer_sizes=(16,), activation=\"relu\", learning_rate_init=0.001, random_state=42, max_iter=1000)\n",
        "print(\"Model 1 (Basit) oluÅŸturuldu.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 1 â€“ Basit YapÄ±da MLP SÄ±nÄ±flandÄ±rÄ±cÄ±\n",
        "\n",
        "Bu aÅŸamada gÃ¶ÄŸÃ¼s kanseri veri seti Ã¼zerinde kullanÄ±lmak Ã¼zere ilk yapay sinir aÄŸÄ± modeli oluÅŸturulmuÅŸtur. Model, basit mimarili bir MLPClassifier (Multi-Layer Perceptron) kullanmaktadÄ±r.\n",
        "\n",
        "**Model AyarlarÄ±**\n",
        "\n",
        "Model 1â€™in yapÄ±landÄ±rmasÄ± ÅŸu ÅŸekildedir:\n",
        "\n",
        "**hidden_layer_sizes = (16,)**\n",
        "â†’ Tek gizli katman, 16 nÃ¶ron\n",
        "\n",
        "**activation = \"relu\"**\n",
        "â†’ ReLU aktivasyon fonksiyonu\n",
        "\n",
        "**learning_rate_init = 0.001**\n",
        "â†’ BaÅŸlangÄ±Ã§ Ã¶ÄŸrenme oranÄ±\n",
        "\n",
        "**max_iter = 1000**\n",
        "â†’ Model en fazla 1000 iterasyon boyunca eÄŸitilebilir\n",
        "\n",
        "**random_state = 42**\n",
        "â†’ ReprodÃ¼ksiyon iÃ§in sabit rastgelelik\n",
        "\n",
        "Bu model, daha karmaÅŸÄ±k mimarilerle karÅŸÄ±laÅŸtÄ±rmak iÃ§in temel (baseline) olarak kullanÄ±lacaktÄ±r."
      ],
      "metadata": {
        "id": "qR_ecbDqx9Yo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4f9a9c64"
      },
      "outputs": [],
      "source": [
        "# Model 2 â€“ Orta\n",
        "# hidden_layer_sizes=(32, 16)\n",
        "# activation=\"relu\"\n",
        "# learning_rate_init=0.005\n",
        "mlp_model_2 = MLPClassifier(hidden_layer_sizes=(32, 16), activation=\"relu\", learning_rate_init=0.005, random_state=42, max_iter=1000)\n",
        "print(\"Model 2 (Orta) oluÅŸturuldu.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 2 â€“ Orta DÃ¼zey MLP YapÄ±sÄ±\n",
        "\n",
        "Ä°kinci model, bir Ã¶nceki modele gÃ¶re daha derin ve karmaÅŸÄ±k bir yapÄ±ya sahiptir.\n",
        "AmaÃ§, model kapasitesini artÄ±rarak veri iÃ§indeki daha karmaÅŸÄ±k iliÅŸkilerin Ã¶ÄŸrenilip Ã¶ÄŸrenilemeyeceÄŸini test etmektir.\n",
        "\n",
        "**Model AyarlarÄ±**\n",
        "\n",
        "Model 2â€™nin mimari Ã¶zellikleri:\n",
        "\n",
        "**hidden_layer_sizes = (32, 16)**\n",
        "â†’ Ä°ki gizli katman\n",
        "\n",
        "- **1. katman: 32 nÃ¶ron**\n",
        "\n",
        "- **2. katman: 16 nÃ¶ron**\n",
        "\n",
        "**activation = \"relu\"**\n",
        "â†’ Gizli katmanlarda ReLU aktivasyonu\n",
        "\n",
        "**learning_rate_init = 0.005**\n",
        "â†’ Model 1â€™e gÃ¶re daha yÃ¼ksek Ã¶ÄŸrenme oranÄ±\n",
        "â†’ Daha hÄ±zlÄ± Ã¶ÄŸrenme, ancak aÅŸÄ±rÄ± gÃ¼ncelleme riskine dikkat\n",
        "\n",
        "**max_iter = 1000**\n",
        "â†’ En fazla 1000 iterasyon\n",
        "\n",
        "**random_state = 42**\n",
        "â†’ SonuÃ§larÄ±n tekrarlanabilirliÄŸini saÄŸlar\n",
        "\n",
        "Bu model, hem katman sayÄ±sÄ± hem de Ã¶ÄŸrenme oranÄ± aÃ§Ä±sÄ±ndan orta dÃ¼zey karmaÅŸÄ±klÄ±k sunar."
      ],
      "metadata": {
        "id": "ti3zQVYXyZif"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d668285"
      },
      "outputs": [],
      "source": [
        "# Model 3 â€“ GeniÅŸ\n",
        "# hidden_layer_sizes=(64, 64)\n",
        "# activation=\"tanh\"\n",
        "# learning_rate_init=0.001\n",
        "mlp_model_3 = MLPClassifier(hidden_layer_sizes=(64, 64), activation=\"tanh\", learning_rate_init=0.001, random_state=42, max_iter=1000)\n",
        "print(\"Model 3 (GeniÅŸ) oluÅŸturuldu.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 3 â€“ GeniÅŸ MLP YapÄ±sÄ±\n",
        "\n",
        "Bu model, Ã¶nceki modellere gÃ¶re daha yÃ¼ksek kapasiteye sahip geniÅŸ bir mimari kullanÄ±r.\n",
        "AmaÃ§, daha bÃ¼yÃ¼k nÃ¶ron sayÄ±larÄ±yla modelin Ã¶ÄŸrenme gÃ¼cÃ¼nÃ¼ artÄ±rÄ±p artÄ±rmadÄ±ÄŸÄ±nÄ± incelemektir.\n",
        "\n",
        "**Model AyarlarÄ±**\n",
        "\n",
        "Model 3â€™Ã¼n mimari ve hiperparametre Ã¶zellikleri:\n",
        "\n",
        "**hidden_layer_sizes = (64, 64)**\n",
        "â†’ Ä°ki bÃ¼yÃ¼k gizli katman\n",
        "\n",
        "- **1. katman: 64 nÃ¶ron**\n",
        "\n",
        "- **2. katman: 64 nÃ¶ron**\n",
        "â†’ Bu yapÄ± daha karmaÅŸÄ±k iliÅŸkileri Ã¶ÄŸrenmeye olanak saÄŸlar.\n",
        "\n",
        "**activation = \"tanh\"**\n",
        "â†’ Tanh aktivasyonu, Ã¶zellikle geniÅŸ katmanlarda daha yumuÅŸak geÃ§iÅŸler saÄŸlayabilir.\n",
        "â†’ ReLUâ€™ya alternatif olarak denenmiÅŸtir.\n",
        "\n",
        "**learning_rate_init = 0.001**\n",
        "â†’ Daha dÃ¼ÅŸÃ¼k Ã¶ÄŸrenme oranÄ±\n",
        "â†’ Daha stabil ama daha yavaÅŸ Ã¶ÄŸrenme saÄŸlar.\n",
        "\n",
        "**max_iter = 1000**\n",
        "â†’ En fazla 1000 iterasyon\n",
        "\n",
        "**random_state = 42**\n",
        "â†’ ReprodÃ¼ksiyon (tekrar edilebilirlik) iÃ§in\n",
        "\n",
        "Bu model, bÃ¼yÃ¼k nÃ¶ron sayÄ±larÄ±na sahip olduÄŸundan yÃ¼ksek karmaÅŸÄ±klÄ±k iÃ§erir ve Ã¶zellikle doÄŸruluk, kayÄ±p eÄŸrisi ve aÅŸÄ±rÄ± Ã¶ÄŸrenme (overfitting) riski bakÄ±mÄ±ndan Ã¶nemlidir."
      ],
      "metadata": {
        "id": "jlzDqUEjy6HI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f857d881"
      },
      "outputs": [],
      "source": [
        "# Model 4 â€“ Derin\n",
        "# hidden_layer_sizes=(128, 64, 32)\n",
        "# activation=\"relu\"\n",
        "# learning_rate_init=0.0005\n",
        "mlp_model_4 = MLPClassifier(hidden_layer_sizes=(128, 64, 32), activation=\"relu\", learning_rate_init=0.0005, random_state=42, max_iter=1000)\n",
        "print(\"Model 4 (Derin) oluÅŸturuldu.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 4 â€“ Derin MLP YapÄ±sÄ±\n",
        "\n",
        "Model 4, Ã¶nceki modellerden daha katmanlÄ± ve daha derin bir mimari kullanÄ±r.\n",
        "AmaÃ§, daha fazla gizli katman eklemenin model performansÄ±na etkisini incelemektir.\n",
        "\n",
        "**Model AyarlarÄ±**\n",
        "\n",
        "Bu modelin hiperparametre ve mimari Ã¶zellikleri:\n",
        "\n",
        "**hidden_layer_sizes = (128, 64, 32)**\n",
        "â†’ ÃœÃ§ gizli katmandan oluÅŸan derin bir model\n",
        "\n",
        "- **1. Katman: 128 nÃ¶ron**\n",
        "\n",
        "- **2. Katman: 64 nÃ¶ron**\n",
        "\n",
        "- **3. Katman: 32 nÃ¶ron**\n",
        "â†’ Derinlik artÄ±rÄ±larak modelin veri Ã¶zelliklerini daha ayrÄ±ntÄ±lÄ± Ã¶ÄŸrenmesi amaÃ§lanmÄ±ÅŸtÄ±r.\n",
        "\n",
        "**activation = \"relu\"**\n",
        "â†’ ReLU, derin yapÄ±lar iÃ§in yaygÄ±n kullanÄ±lan hÄ±zlÄ± ve stabil bir aktivasyon fonksiyonudur.\n",
        "â†’ Ã–zellikle bÃ¼yÃ¼k katmanlarda Ã¶ÄŸrenme sÃ¼recini hÄ±zlandÄ±rÄ±r.\n",
        "\n",
        "**learning_rate_init = 0.0005**\n",
        "â†’ Daha dÃ¼ÅŸÃ¼k bir Ã¶ÄŸrenme oranÄ± seÃ§ilmiÅŸtir.\n",
        "â†’ Derin modellerde patlayan gradyan ve hÄ±zlÄ± bozulmayÄ± Ã¶nlemek iÃ§in uygundur.\n",
        "\n",
        "**max_iter = 1000**\n",
        "â†’ Modelin daha uzun sÃ¼re Ã¶ÄŸrenmesine izin verilir.\n",
        "\n",
        "**random_state = 42**\n",
        "â†’ SonuÃ§larÄ±n tekrar Ã¼retilebilir olmasÄ±nÄ± saÄŸlar.\n",
        "\n",
        "Model 4, derin ve Ã§ok katmanlÄ± yapÄ±sÄ±yla daha esnek bir Ã¶ÄŸrenme kapasitesine sahiptir. Ancak bu tÃ¼r modellerde overfitting riski ve eÄŸitim sÃ¼resinin artmasÄ± yaygÄ±n olarak gÃ¶zlemlenebilir."
      ],
      "metadata": {
        "id": "_10gCRLMzcP2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "629bc5e5"
      },
      "outputs": [],
      "source": [
        "# Model 5 â€“ DÃ¼ÅŸÃ¼k Ã–ÄŸrenme OranlÄ±\n",
        "# hidden_layer_sizes=(32,)\n",
        "# activation=\"relu\"\n",
        "# learning_rate_init=0.0001\n",
        "mlp_model_5 = MLPClassifier(hidden_layer_sizes=(32,), activation=\"relu\", learning_rate_init=0.0001, random_state=42, max_iter=1000)\n",
        "print(\"Model 5 (DÃ¼ÅŸÃ¼k Ã–ÄŸrenme OranlÄ±) oluÅŸturuldu.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 5 â€“ DÃ¼ÅŸÃ¼k Ã–ÄŸrenme OranlÄ± MLP\n",
        "\n",
        "Bu model, basit bir mimariye sahip olmasÄ±na raÄŸmen Ã§ok dÃ¼ÅŸÃ¼k Ã¶ÄŸrenme oranÄ± ile yapÄ±landÄ±rÄ±lmÄ±ÅŸtÄ±r.\n",
        "AmaÃ§, Ã¶ÄŸrenme oranÄ±nÄ±n model performansÄ± Ã¼zerindeki etkisini gÃ¶zlemlemektir.\n",
        "\n",
        "###**Model AyarlarÄ±**\n",
        "\n",
        "**hidden_layer_sizes = (32,)**\n",
        "â†’ Tek gizli katman, 32 nÃ¶ron\n",
        "\n",
        "**activation = \"relu\"**\n",
        "â†’ ReLU aktivasyon fonksiyonu kullanÄ±lmÄ±ÅŸtÄ±r.\n",
        "\n",
        "**learning_rate_init = 0.0001**\n",
        "â†’ Ã‡ok dÃ¼ÅŸÃ¼k baÅŸlangÄ±Ã§ Ã¶ÄŸrenme oranÄ±\n",
        "â†’ Modelin daha yavaÅŸ, ama stabil Ã¶ÄŸrenmesini saÄŸlar.\n",
        "\n",
        "**max_iter = 1000**\n",
        "â†’ En fazla 1000 iterasyon\n",
        "\n",
        "**random_state = 42**\n",
        "â†’ SonuÃ§larÄ±n tekrar edilebilirliÄŸi iÃ§in\n",
        "\n",
        "Bu model, Ã¶zellikle yavaÅŸ Ã¶ÄŸrenen ve aÅŸÄ±rÄ± gÃ¼ncellemelerden kaÃ§Ä±nan senaryolar iÃ§in tasarlanmÄ±ÅŸtÄ±r."
      ],
      "metadata": {
        "id": "vtDqUSd1z6g7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb114142"
      },
      "source": [
        "## 7. Validation PerformanslarÄ±nÄ±n Ã–lÃ§Ã¼lmesi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3a38e29"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import pandas as pd\n",
        "\n",
        "# TanÄ±mlanmÄ±ÅŸ modelleri bir listede toplayalÄ±m\n",
        "models = {\n",
        "    \"Model 1 (Basit)\": mlp_model_1,\n",
        "    \"Model 2 (Orta)\": mlp_model_2,\n",
        "    \"Model 3 (GeniÅŸ)\": mlp_model_3,\n",
        "    \"Model 4 (Derin)\": mlp_model_4,\n",
        "    \"Model 5 (DÃ¼ÅŸÃ¼k Ã–ÄŸrenme OranlÄ±)\": mlp_model_5\n",
        "}\n",
        "\n",
        "# SonuÃ§larÄ± depolamak iÃ§in boÅŸ bir DataFrame oluÅŸturalÄ±m\n",
        "performance_metrics = pd.DataFrame(columns=[\n",
        "    'Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC'\n",
        "])\n",
        "\n",
        "# Her modeli eÄŸitelim ve doÄŸrulama seti Ã¼zerinde deÄŸerlendirelim\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n{name} eÄŸitiliyor...\")\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # DoÄŸrulama seti Ã¼zerinde tahminler yapalÄ±m\n",
        "    y_pred = model.predict(X_val)\n",
        "    y_proba = model.predict_proba(X_val)[:, 1] # ROC-AUC iÃ§in pozitif sÄ±nÄ±f olasÄ±lÄ±klarÄ±\n",
        "\n",
        "    # Metrikleri hesaplayalÄ±m\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    precision = precision_score(y_val, y_predbu adÄ±m, zero_division=0)\n",
        "    recall = recall_score(y_val, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_val, y_pred, zero_division=0)\n",
        "    roc_auc = roc_auc_score(y_val, y_proba)\n",
        "\n",
        "    # SonuÃ§larÄ± DataFrame'e ekleyelim\n",
        "    performance_metrics.loc[len(performance_metrics)] = [\n",
        "        name, accuracy, precision, recall, f1, roc_auc\n",
        "    ]\n",
        "\n",
        "# Performans metrikleri tablosunu gÃ¶rÃ¼ntÃ¼leyelim\n",
        "print(\"\\n--- Model PerformanslarÄ± (Validation Set) ---\")\n",
        "display(performance_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94e259d1"
      },
      "source": [
        "##MLP Modellerinin Performans KarÅŸÄ±laÅŸtÄ±rmasÄ± (Validation Set) SonuÃ§larÄ±nÄ±n Yorumu\n",
        "\n",
        "YukarÄ±daki tabloya gÃ¶re, farklÄ± mimarilere sahip MLP modellerinin doÄŸrulama seti Ã¼zerindeki performanslarÄ± aÅŸaÄŸÄ±daki gibi yorumlanabilir:\n",
        "\n",
        "*   **MÃ¼kemmel Performans GÃ¶steren Modeller (Model 1 ve Model 5):**\n",
        "    *   `Model 1 (Basit)` ve `Model 5 (DÃ¼ÅŸÃ¼k Ã–ÄŸrenme OranlÄ±)` doÄŸrulama setinde tÃ¼m metriklerde (Accuracy, Precision, Recall, F1-Score, ROC-AUC) **%100** oranÄ±nda mÃ¼kemmel bir performans sergilemiÅŸlerdir.\n",
        "    *   Bu durum, veri setinin bu modeller iÃ§in oldukÃ§a iyi ayrÄ±ÅŸtÄ±rÄ±labilir olduÄŸunu veya basit modellerin bile bu spesifik gÃ¶rev iÃ§in yeterli olduÄŸunu gÃ¶stermektedir.\n",
        "    *   `Model 5`'in dÃ¼ÅŸÃ¼k Ã¶ÄŸrenme oranÄ±yla bile benzer bir baÅŸarÄ± elde etmesi, stabil ve dikkatli Ã¶ÄŸrenme stratejisinin de bu veri setinde etkili olduÄŸunu iÅŸaret eder.\n",
        "\n",
        "*   **YÃ¼ksek PerformanslÄ± DiÄŸer Modeller (Model 2, 3, 4):**\n",
        "    *   `Model 2 (Orta)` ve `Model 4 (Derin)` %98.21 Accuracy ve 1.0000 ROC-AUC deÄŸerleriyle Ã§ok gÃ¼Ã§lÃ¼ performans gÃ¶stermiÅŸlerdir. `Model 3 (GeniÅŸ)` ise %96.43 Accuracy ile biraz daha dÃ¼ÅŸÃ¼k olsa da hala oldukÃ§a baÅŸarÄ±lÄ±dÄ±r.\n",
        "    *   Bu modeller, daha karmaÅŸÄ±k mimarilere sahip olmalarÄ±na raÄŸmen, Model 1 ve Model 5'in gÃ¶sterdiÄŸi mÃ¼kemmeliyete doÄŸrulama setinde ulaÅŸamamÄ±ÅŸlardÄ±r. Bu, daha karmaÅŸÄ±k yapÄ±larÄ±n her zaman daha iyi performans anlamÄ±na gelmediÄŸini veya bu veri seti iÃ§in ek karmaÅŸÄ±klÄ±ÄŸÄ±n getirisinin sÄ±nÄ±rlÄ± olduÄŸunu dÃ¼ÅŸÃ¼ndÃ¼rebilir.\n",
        "\n",
        "**Genel DeÄŸerlendirme:**\n",
        "\n",
        "DoÄŸrulama setindeki bu sonuÃ§lar, tÃ¼m MLP modellerinin meme kanseri veri setini sÄ±nÄ±flandÄ±rma gÃ¶revinde genel olarak Ã§ok iyi bir performans sergilediÄŸini gÃ¶stermektedir. Ã–zellikle `Model 1 (Basit)` ve `Model 5 (DÃ¼ÅŸÃ¼k Ã–ÄŸrenme OranlÄ±)`'nÄ±n gÃ¶sterdiÄŸi %100'lÃ¼k skorlar, veri setinin MLP modelleriyle oldukÃ§a baÅŸarÄ±lÄ± bir ÅŸekilde Ã§Ã¶zÃ¼lebileceÄŸini ortaya koymuÅŸtur.\n",
        "\n",
        "Ancak, doÄŸrulama setinde elde edilen bu mÃ¼kemmel performansÄ±n, modelin genellenebilirliÄŸi aÃ§Ä±sÄ±ndan potansiyel bir *aÅŸÄ±rÄ± uyum (overfitting)* riskini de beraberinde getirebileceÄŸi unutulmamalÄ±dÄ±r. Bu nedenle, test seti Ã¼zerindeki nihai performans deÄŸerlendirmesi, modelin gerÃ§ek dÃ¼nya verilerindeki baÅŸarÄ±sÄ±nÄ± anlamak iÃ§in kritik Ã¶neme sahiptir."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MLP Modellerinin Performans KarÅŸÄ±laÅŸtÄ±rmasÄ± (Validation Set)\n",
        "\n",
        "Bu bÃ¶lÃ¼mde, daha Ã¶nce oluÅŸturulan 5 MLP modelinin doÄŸrulama (validation) seti Ã¼zerindeki performanslarÄ± deÄŸerlendirilmiÅŸtir.\n",
        "KullanÄ±lan performans metrikleri:\n",
        "\n",
        "**Accuracy**: DoÄŸru sÄ±nÄ±flandÄ±rma oranÄ±\n",
        "\n",
        "**Precision**: Pozitif sÄ±nÄ±flandÄ±rmanÄ±n doÄŸruluk oranÄ±\n",
        "\n",
        "**Recall**: Pozitif sÄ±nÄ±flandÄ±rmalarÄ±n ne kadarÄ±nÄ±n doÄŸru tespit edildiÄŸi\n",
        "\n",
        "**F1-Score**: Precision ve Recallâ€™un harmonik ortalamasÄ±\n",
        "\n",
        "**ROC-AUC**: Modelin sÄ±nÄ±flarÄ± ayÄ±rt etme baÅŸarÄ±sÄ±\n",
        "\n",
        "**Modellerin EÄŸitimi**:\n",
        "Her model X_train ve y_train kullanÄ±larak eÄŸitilir.\n",
        "\n",
        "**Tahminler ve OlasÄ±lÄ±klar**:\n",
        "\n",
        "**y_pred**: DoÄŸrulama seti Ã¼zerinde sÄ±nÄ±f tahminleri\n",
        "\n",
        "**y_proba**: ROC-AUC metriÄŸi iÃ§in pozitif sÄ±nÄ±fÄ±n olasÄ±lÄ±k tahminleri\n",
        "\n",
        "**Metriklerin HesaplanmasÄ±**:\n",
        "\n",
        "**accuracy_score** â†’ Genel doÄŸruluk\n",
        "\n",
        "**precision_score **â†’ Pozitif sÄ±nÄ±flarÄ±n doÄŸruluÄŸu\n",
        "\n",
        "**recall_score** â†’ Pozitif sÄ±nÄ±flarÄ±n tespit oranÄ±\n",
        "\n",
        "**f1_score** â†’ Precision ve Recallâ€™un dengeli ortalamasÄ±\n",
        "\n",
        "**roc_auc_score** â†’ Modelin sÄ±nÄ±flarÄ± ayÄ±rt etme yeteneÄŸi\n",
        "\n",
        "**SonuÃ§larÄ±n Tablo Halinde GÃ¶sterimi**:\n",
        "TÃ¼m modellerin performans metrikleri tek bir DataFrameâ€™de toplanÄ±r ve karÅŸÄ±laÅŸtÄ±rmaya hazÄ±r hale getirilir."
      ],
      "metadata": {
        "id": "WO8nmn1E0gxo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f47471a1"
      },
      "source": [
        "## 8. En Ä°yi Modelin Test Ãœzerinde DeÄŸerlendirilmesi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec55956f"
      },
      "source": [
        "DoÄŸrulama setindeki mÃ¼kemmel performansÄ±na dayanarak **Model 1 (Basit)**'i en iyi model olarak seÃ§iyoruz. Åimdi bu modelin test seti Ã¼zerindeki performansÄ±nÄ± deÄŸerlendirelim."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d26ccac"
      },
      "outputs": [],
      "source": [
        "# En iyi modeli seÃ§ (Validation setinde en iyi performansÄ± gÃ¶steren Model 1)\n",
        "best_model = mlp_model_1\n",
        "\n",
        "print(\"SeÃ§ilen En Ä°yi Model: Model 1 (Basit)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##En Ä°yi Modelin SeÃ§imi\n",
        "\n",
        "Validation seti Ã¼zerinde yapÄ±lan performans karÅŸÄ±laÅŸtÄ±rmalarÄ±na gÃ¶re en iyi sonuÃ§larÄ± veren model seÃ§ilmiÅŸtir.\n",
        "Bu model, ileride test seti Ã¼zerinde nihai performans deÄŸerlendirmesi iÃ§in kullanÄ±lacaktÄ±r.\n",
        "\n",
        "###SeÃ§ilen Model\n",
        "\n",
        "- **Model 1 (Basit)**\n",
        "\n",
        "- **Tek gizli katman (16 nÃ¶ron)**\n",
        "\n",
        "- **ReLU aktivasyonu**\n",
        "\n",
        "- **Ã–ÄŸrenme oranÄ±: 0.001**\n",
        "\n",
        "SeÃ§im, validation setindeki metrikler (accuracy, F1-score, ROC-AUC vb.) gÃ¶z Ã¶nÃ¼nde bulundurularak yapÄ±lmÄ±ÅŸtÄ±r."
      ],
      "metadata": {
        "id": "mpPRd6FS1HOI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cdef1ba"
      },
      "source": [
        "### 8.1 Performans Metrikleri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "888f6694"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Test seti Ã¼zerinde tahminler yapalÄ±m\n",
        "y_pred_test = best_model.predict(X_test)\n",
        "y_proba_test = best_model.predict_proba(X_test)[:, 1] # ROC-AUC iÃ§in pozitif sÄ±nÄ±f olasÄ±lÄ±klarÄ±\n",
        "\n",
        "# Metrikleri hesaplayalÄ±m\n",
        "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
        "precision_test = precision_score(y_test, y_pred_test, zero_division=0)\n",
        "recall_test = recall_score(y_test, y_pred_test, zero_division=0)\n",
        "f1_test = f1_score(y_test, y_pred_test, zero_division=0)\n",
        "roc_auc_test = roc_auc_score(y_test, y_proba_test)\n",
        "\n",
        "# SonuÃ§larÄ± gÃ¶rÃ¼ntÃ¼leyelim\n",
        "print(\"--- En Ä°yi Model PerformansÄ± (Test Seti) ---\")\n",
        "print(f\"Accuracy:  {accuracy_test:.4f}\")\n",
        "print(f\"Precision: {precision_test:.4f}\")\n",
        "print(f\"Recall:    {recall_test:.4f}\")\n",
        "print(f\"F1-Score:  {f1_test:.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc_test:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##En Ä°yi Modelin Test Seti PerformansÄ±\n",
        "\n",
        "SeÃ§ilen en iyi model (Model 1 â€“ Basit) artÄ±k test seti Ã¼zerinde deÄŸerlendirilmiÅŸtir.\n",
        "Test seti, modelin daha Ã¶nce gÃ¶rmediÄŸi veri Ã¼zerinde gerÃ§ek performansÄ±nÄ± Ã¶lÃ§mek iÃ§in kullanÄ±lÄ±r.\n",
        "\n",
        "###Performans Metrikleri (Test Seti)\n",
        "\n",
        "**Accuracy**: DoÄŸru sÄ±nÄ±flandÄ±rma oranÄ±\n",
        "\n",
        "**Precision**: Pozitif sÄ±nÄ±flandÄ±rmanÄ±n doÄŸruluk oranÄ±\n",
        "\n",
        "**Recall**: Pozitif sÄ±nÄ±flandÄ±rmalarÄ±n ne kadarÄ±nÄ±n doÄŸru tespit edildiÄŸi\n",
        "\n",
        "**F1-Score**: Precision ve Recallâ€™un harmonik ortalamasÄ±\n",
        "\n",
        "**ROC-AUC**: Modelin sÄ±nÄ±flarÄ± ayÄ±rt etme baÅŸarÄ±sÄ±\n",
        "\n",
        "---\n",
        "###AÃ§Ä±klama\n",
        "\n",
        "**Test Seti KullanÄ±mÄ±:**\n",
        "\n",
        "Model, eÄŸitim ve doÄŸrulama seti dÄ±ÅŸÄ±nda kalan X_test ve y_test Ã¼zerinde deÄŸerlendirilmiÅŸtir.\n",
        "\n",
        "BÃ¶ylece modelin genel performansÄ± ve genelleme yeteneÄŸi Ã¶lÃ§Ã¼lÃ¼r.\n",
        "\n",
        "**Tahminler ve OlasÄ±lÄ±klar**:\n",
        "\n",
        "- **y_pred_test: SÄ±nÄ±f tahminleri**\n",
        "\n",
        "- **y_proba_test: Pozitif sÄ±nÄ±f olasÄ±lÄ±k tahminleri (ROC-AUC iÃ§in)**\n",
        "\n",
        "**Metriklerin Yorumu:**\n",
        "\n",
        "**Accuracy**: Modelin tÃ¼m sÄ±nÄ±flarda doÄŸru tahmin oranÄ±\n",
        "\n",
        "**Precision**: Pozitif tahminlerin doÄŸruluk oranÄ±\n",
        "\n",
        "**Recall**: GerÃ§ek pozitiflerin doÄŸru tahmin edilme oranÄ±\n",
        "\n",
        "**F1-Score**: Precision ve Recall dengesi\n",
        "\n",
        "**ROC-AUC**: Modelin sÄ±nÄ±flarÄ± ayÄ±rt etme baÅŸarÄ±sÄ±"
      ],
      "metadata": {
        "id": "NHedCZbC16BR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "413e5ed5"
      },
      "source": [
        "### 8.2 Confusion Matrix (KarÄ±ÅŸÄ±klÄ±k Matrisi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "be1b5698"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# KarÄ±ÅŸÄ±klÄ±k matrisini hesapla\n",
        "cm = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "# KarÄ±ÅŸÄ±klÄ±k matrisini gÃ¶rselleÅŸtir\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Malign (0)', 'Benign (1)'],\n",
        "            yticklabels=['Malign (0)', 'Benign (1)'])\n",
        "plt.xlabel('Tahmin Edilen SÄ±nÄ±f')\n",
        "plt.ylabel('GerÃ§ek SÄ±nÄ±f')\n",
        "plt.title('KarÄ±ÅŸÄ±klÄ±k Matrisi (Test Seti)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##KarÄ±ÅŸÄ±klÄ±k Matrisi (Confusion Matrix) â€“ Test Seti\n",
        "\n",
        "KarÄ±ÅŸÄ±klÄ±k matrisi, modelin hangi sÄ±nÄ±flarÄ± doÄŸru veya yanlÄ±ÅŸ tahmin ettiÄŸini detaylÄ± olarak gÃ¶sterir.\n",
        "Pozitif ve negatif sÄ±nÄ±flarÄ±n doÄŸru ve yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rÄ±lmalarÄ±nÄ± tablo ve gÃ¶rselleÅŸtirme ile inceleyebiliriz.\n",
        "\n",
        "###GÃ¶rselleÅŸtirme Ã–zellikleri\n",
        "\n",
        "**xticklabels / yticklabels**:\n",
        "\n",
        "**0** â†’ Malign\n",
        "\n",
        "**1** â†’ Benign\n",
        "\n",
        "**annot=True**: Matris hÃ¼crelerine sayÄ±larÄ±n yazÄ±lmasÄ±\n",
        "\n",
        "**fmt='d'**: TamsayÄ± formatÄ±nda gÃ¶sterim\n",
        "\n",
        "**cmap='Blues'**: Renk skalasÄ±\n",
        "\n",
        "Bu gÃ¶rselleÅŸtirme, modelin hangi sÄ±nÄ±fta ne kadar doÄŸru tahmin yaptÄ±ÄŸÄ±nÄ± hÄ±zlÄ±ca anlamamÄ±zÄ± saÄŸlar.\n",
        "\n",
        "###AÃ§Ä±klama\n",
        "\n",
        "\n",
        "**cm[0,0]** â†’ GerÃ§ek Malign, doÄŸru tahmin edilen Malign sayÄ±sÄ±\n",
        "\n",
        "\n",
        "**cm[0,1]** â†’ GerÃ§ek Malign, yanlÄ±ÅŸ tahmin edilen Benign sayÄ±sÄ±\n",
        "\n",
        "\n",
        "**cm[1,0]** â†’ GerÃ§ek Benign, yanlÄ±ÅŸ tahmin edilen Malign sayÄ±sÄ±\n",
        "\n",
        "\n",
        "**cm[1,1]**â†’ GerÃ§ek Benign, doÄŸru tahmin edilen Benign sayÄ±sÄ±\n",
        "\n",
        "\n",
        "Bu matris, Ã¶zellikle yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rmalarÄ±n analizinde ve modelin hangi sÄ±nÄ±fta zorlandÄ±ÄŸÄ±nÄ± gÃ¶rmekte faydalÄ±dÄ±r."
      ],
      "metadata": {
        "id": "ypyF2sI-V5wJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c506bb79"
      },
      "source": [
        "### 8.3 ROC EÄŸrisi ve AUC DeÄŸeri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cc9ecc8"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# ROC eÄŸrisi iÃ§in False Positive Rate (FPR) ve True Positive Rate (TPR) deÄŸerlerini hesapla\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_proba_test)\n",
        "\n",
        "# AUC (Area Under the Curve) deÄŸerini hesapla\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# ROC EÄŸrisini Ã§iz\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Rastgele SÄ±nÄ±flandÄ±rÄ±cÄ±')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('YanlÄ±ÅŸ Pozitif OranÄ± (False Positive Rate)')\n",
        "plt.ylabel('DoÄŸru Pozitif OranÄ± (True Positive Rate)')\n",
        "plt.title('ROC EÄŸrisi (Test Seti)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Test Seti AUC DeÄŸeri: {roc_auc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ROC EÄŸrisi ve AUC â€“ Test Seti\n",
        "\n",
        "ROC (Receiver Operating Characteristic) eÄŸrisi, modelin farklÄ± eÅŸik deÄŸerlerinde sÄ±nÄ±flarÄ± ayÄ±rt etme yeteneÄŸini gÃ¶sterir.\n",
        "AUC (Area Under the Curve) deÄŸeri ise ROC eÄŸrisinin altÄ±nda kalan alanÄ± temsil eder ve modelin genel ayÄ±rt etme baÅŸarÄ±sÄ±nÄ± Ã¶zetler.\n",
        "\n",
        "**Kod AÃ§Ä±klamasÄ± ve Ä°ÅŸlevi**\n",
        "\n",
        "ROC EÄŸrisi iÃ§in hesaplamalar:\n",
        "\n",
        "**fpr**â†’ False Positive Rate (YanlÄ±ÅŸ Pozitif OranÄ±)\n",
        "\n",
        "**tpr** â†’ True Positive Rate (DoÄŸru Pozitif OranÄ±)\n",
        "\n",
        "**thresholds** â†’ FarklÄ± eÅŸik deÄŸerleri\n",
        "\n",
        "**AUC Hesaplama**:\n",
        "\n",
        "- **roc_auc** = auc(fpr, tpr)\n",
        "\n",
        "- **DeÄŸer 0.5** â†’ Rastgele sÄ±nÄ±flandÄ±rÄ±cÄ±\n",
        "\n",
        "- **DeÄŸer 1.0** â†’ MÃ¼kemmel sÄ±nÄ±flandÄ±rÄ±cÄ±\n",
        "\n",
        "**EÄŸri GÃ¶rselleÅŸtirme:**\n",
        "\n",
        "ROC eÄŸrisi turuncu Ã§izgi ile gÃ¶sterilir\n",
        "\n",
        "Rastgele sÄ±nÄ±flandÄ±rÄ±cÄ± referans Ã§izgisi mavi kesikli Ã§izgi ile gÃ¶sterilir\n",
        "\n",
        "Grafikte eksenler ve grid ile okunabilirlik artÄ±rÄ±lÄ±r\n",
        "\n",
        "###AÃ§Ä±klama\n",
        "\n",
        "- ROC eÄŸrisi, modelin farklÄ± eÅŸiklerdeki duyarlÄ±lÄ±k ve Ã¶zgÃ¼llÃ¼ÄŸÃ¼nÃ¼ gÃ¶rselleÅŸtirir.\n",
        "\n",
        "- AUC deÄŸeri, modelin genel ayÄ±rt etme yeteneÄŸini tek bir sayÄ±yla Ã¶zetler:\n",
        "\n",
        "- 0.5 â†’ Rastgele tahmin\n",
        "\n",
        "- 1.0 â†’ MÃ¼kemmel tahmin\n",
        "\n",
        "Bu grafik ve AUC deÄŸeri, en iyi modelin test setindeki genel performansÄ±nÄ± ve sÄ±nÄ±flar arasÄ±ndaki ayrÄ±m yeteneÄŸini deÄŸerlendirmede oldukÃ§a faydalÄ±dÄ±r."
      ],
      "metadata": {
        "id": "Rh5rB0EUW8WR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9umKVKoT2mK"
      },
      "source": [
        "9. # Optuna ile Hiperparametre Optimizasyonu (150 Deneme)\n",
        "\n",
        "\n",
        "###9.1 Optuna Study TanÄ±mÄ±\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBhkJz5dVzMQ"
      },
      "outputs": [],
      "source": [
        "!pip install optuna\n",
        "import optuna\n",
        "\n",
        "# Optuna study tanÄ±mÄ±\n",
        "# direction='maximize' ile validation accuracy'yi maksimize etmeyi hedefliyoruz.\n",
        "study = optuna.create_study(direction='maximize', study_name='MLP_Hyperparameter_Optimization')\n",
        "\n",
        "print(\"Optuna study baÅŸvurusu oluÅŸturuldu.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu aÅŸamada henÃ¼z hiperparametre optimizasyonu baÅŸlamadÄ±, sadece bir study nesnesi oluÅŸturuldu.\n",
        "\n",
        "Bir sonraki adÄ±mda objective fonksiyonu tanÄ±mlanarak, Ã¶ÄŸrenme oranÄ±, gizli katman sayÄ±sÄ±/nÃ¶ron sayÄ±sÄ± gibi MLP hiperparametreleri optimize edilecektir.\n",
        "\n",
        "Bu Ã§alÄ±ÅŸma, MLP modelinin validation set performansÄ±nÄ± maksimize eden en iyi hiperparametreleri otomatik olarak bulmayÄ± saÄŸlar."
      ],
      "metadata": {
        "id": "hOfFo4QlXqLV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e37bcad9"
      },
      "source": [
        "\n",
        "###9.2 Optuna Arama AralÄ±klarÄ±\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4581e370"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    # hidden_layer_sizes: (trial.suggest_int(16, 256), trial.suggest_int(8, 128))\n",
        "    n_layers = trial.suggest_int('n_layers', 1, 3)\n",
        "    hidden_layer_sizes = []\n",
        "    for i in range(n_layers):\n",
        "        if i == 0:\n",
        "            hidden_layer_sizes.append(trial.suggest_int(f'n_units_l{i}', 16, 256))\n",
        "        else:\n",
        "            hidden_layer_sizes.append(trial.suggest_int(f'n_units_l{i}', 8, 128))\n",
        "\n",
        "    # learning_rate_init: trial.suggest_loguniform(1e-5, 1e-1)\n",
        "    learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-5, 1e-1)\n",
        "\n",
        "    # alpha: trial.suggest_loguniform(1e-6, 1e-2)\n",
        "    alpha = trial.suggest_loguniform('alpha', 1e-6, 1e-2)\n",
        "\n",
        "    # activation: trial.suggest_categorical(['relu', 'tanh'])\n",
        "    activation = trial.suggest_categorical('activation', ['relu', 'tanh'])\n",
        "\n",
        "    # solver: trial.suggest_categorical(['adam', 'sgd'])\n",
        "    solver = trial.suggest_categorical('solver', ['adam', 'sgd'])\n",
        "\n",
        "    # batch_size: trial.suggest_categorical([16, 32, 64, 128]) - MLPClassifier'da doÄŸrudan parametre olarak geÃ§mez.\n",
        "    # MLPClassifier iÃ§in batch_size genellikle 'max_iter' ve 'tol' ile dolaylÄ± kontrol edilir.\n",
        "    # Bu nedenle, MLPClassifier'Ä±n kendi parametresi olarak batch_size Ã¶nermek yerine,\n",
        "    # Optuna optimizasyonu iÃ§in diÄŸer hiperparametreleri belirledik.\n",
        "\n",
        "    model = MLPClassifier(\n",
        "        hidden_layer_sizes=tuple(hidden_layer_sizes),\n",
        "        activation=activation,\n",
        "        solver=solver,\n",
        "        alpha=alpha,\n",
        "        learning_rate_init=learning_rate_init,\n",
        "        max_iter=1000, # Maksimum iterasyon sayÄ±sÄ±nÄ± sabit tutalÄ±m\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Validation accuracy'yi dÃ¶ndÃ¼rÃ¼yoruz\n",
        "    y_pred = model.predict(X_val)\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "print(\"Optuna hedef fonksiyonu (objective), belirtilen arama aralÄ±klarÄ± ile birlikte tanÄ±mlandÄ±.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu bÃ¶lÃ¼mde MLP hiperparametre optimizasyonu iÃ§in objective fonksiyonu tanÄ±mlanmÄ±ÅŸtÄ±r.\n",
        "Objective fonksiyon, Optunaâ€™nÄ±n deneme (trial) bazlÄ± arama sÃ¼recinde validation accuracyâ€™yi maksimize etmeyi hedefler.\n",
        "\n",
        "---\n",
        "##Fonksiyon AÃ§Ä±klamasÄ±\n",
        "\n",
        "1. **Katman ve NÃ¶ron SayÄ±sÄ±:**\n",
        "\n",
        "n_layers = trial.suggest_int('n_layers', 1, 3)\n",
        "hidden_layer_sizes = []\n",
        "for i in range(n_layers):\n",
        "    if i == 0:\n",
        "        hidden_layer_sizes.append(trial.suggest_int(f'n_units_l{i}', 16, 256))\n",
        "    else:\n",
        "        hidden_layer_sizes.append(trial.suggest_int(f'n_units_l{i}', 8, 128))\n",
        "- n_layers: 1 ile 3 arasÄ±nda rastgele katman sayÄ±sÄ± seÃ§er\n",
        "\n",
        "- Her katman iÃ§in nÃ¶ron sayÄ±sÄ± farklÄ± aralÄ±klardan seÃ§ilir\n",
        "\n",
        "2. **Ã–ÄŸrenme OranÄ± (learning_rate_init):**\n",
        "\n",
        "learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-5, 1e-1)\n",
        "- Log-uniform daÄŸÄ±lÄ±mdan rastgele seÃ§im yapÄ±lÄ±r\n",
        "- 0.00001 ile 0.1 arasÄ±nda deÄŸiÅŸir\n",
        "\n",
        "3. **Regularizasyon Parametresi (alpha):**\n",
        "\n",
        "alpha = trial.suggest_loguniform('alpha', 1e-6, 1e-2)\n",
        "- L2 ceza terimi, aÅŸÄ±rÄ± Ã¶ÄŸrenmeyi Ã¶nlemek iÃ§in optimize edilir\n",
        "\n",
        "4. **Aktivasyon Fonksiyonu:**\n",
        "\n",
        "activation = trial.suggest_categorical('activation', ['relu', 'tanh'])\n",
        "- Her denemede relu veya tanh seÃ§ilir\n",
        "\n",
        "5. **Ã‡Ã¶zÃ¼cÃ¼ (Solver):**\n",
        "\n",
        "solver = trial.suggest_categorical('solver', ['adam', 'sgd'])\n",
        "- AÄŸÄ±n aÄŸÄ±rlÄ±klarÄ±nÄ± gÃ¼ncellemek iÃ§in farklÄ± optimizasyon algoritmalarÄ± denenir\n",
        "\n",
        "6. **Model EÄŸitimi ve DeÄŸerlendirme:**\n",
        "\n",
        "model = MLPClassifier(\n",
        "    hidden_layer_sizes=tuple(hidden_layer_sizes),\n",
        "    activation=activation,\n",
        "    solver=solver,\n",
        "    alpha=alpha,\n",
        "    learning_rate_init=learning_rate_init,\n",
        "    max_iter=1000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "return accuracy\n",
        "- Model, eÄŸitim setinde fit edilir\n",
        "- Validation setinde tahminler yapÄ±lÄ±r\n",
        "- Validation accuracy objective fonksiyon sonucu olarak dÃ¶ndÃ¼rÃ¼lÃ¼r\n",
        "\n",
        "**Objective Fonksiyon**: Her trialâ€™da rastgele seÃ§ilen hiperparametrelerle MLP modeli oluÅŸturur, eÄŸitir ve validation accuracyâ€™yi dÃ¶ndÃ¼rÃ¼r.\n",
        "\n",
        "\n",
        "Optuna, bu fonksiyonu kullanarak en iyi hiperparametre kombinasyonunu otomatik olarak bulur.\n",
        "\n",
        "\n",
        "Fonksiyon, MLP modelinin katman sayÄ±sÄ±, nÃ¶ron sayÄ±sÄ±, Ã¶ÄŸrenme oranÄ±, alpha, aktivasyon ve solver parametrelerini optimize edecek ÅŸekilde tasarlanmÄ±ÅŸtÄ±r.\n",
        "\n"
      ],
      "metadata": {
        "id": "YfwGRLQlX0Qq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJq_nmFyIQCW"
      },
      "outputs": [],
      "source": [
        "study.optimize(objective, n_trials=150)\n",
        "\n",
        "print(\"\\nOptimizasyon tamamlandÄ±!\")\n",
        "print(f\"En iyi deneme sayÄ±sÄ±: {study.best_trial.number}\")\n",
        "print(f\"En iyi doÄŸruluk (Accuracy): {study.best_trial.value:.4f}\")\n",
        "\n",
        "print(\"\\nEn iyi deneme parametreleri:\")\n",
        "for key, value in study.best_trial.params.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu adÄ±mda, daha Ã¶nce tanÄ±mlanan objective fonksiyon kullanÄ±larak MLP modeli iÃ§in 150 deneme (trial) yapÄ±lmÄ±ÅŸtÄ±r.\n",
        "Optuna, her denemede farklÄ± hiperparametre kombinasyonlarÄ±nÄ± deneyerek validation accuracyâ€™yi maksimize etmeye Ã§alÄ±ÅŸmÄ±ÅŸtÄ±r.\n",
        "\n",
        "**Kod AÃ§Ä±klamasÄ±**\n",
        "\n",
        "**study.optimize(objective, n_trials=150)**\n",
        "- study.optimize â†’ Optuna studyâ€™i Ã§alÄ±ÅŸtÄ±rÄ±r\n",
        "\n",
        "- objective â†’ Hangi fonksiyonun optimize edileceÄŸini belirtir\n",
        "\n",
        "- n_trials=150 â†’ Toplam deneme sayÄ±sÄ±\n",
        "\n",
        "**print(f\"En iyi deneme sayÄ±sÄ±: {study.best_trial.number}\")\n",
        "print(f\"En iyi doÄŸruluk (Accuracy): {study.best_trial.value:.4f}\")**\n",
        "\n",
        "- study.best_trial.number â†’ En iyi performansÄ±n hangi denemede elde edildiÄŸini gÃ¶sterir\n",
        "\n",
        "- study.best_trial.value â†’ En iyi denemedeki validation accuracy deÄŸeri\n",
        "\n",
        "**print(\"\\nEn iyi deneme parametreleri:\")\n",
        "for key, value in study.best_trial.params.items():\n",
        "    print(f\"  {key}: {value}\")**\n",
        "- study.best_trial.params â†’ En iyi denemede kullanÄ±lan hiperparametreler listelenir\n",
        "\n",
        "\n",
        "Bu optimizasyon, modelin hidden layer sayÄ±sÄ± ve nÃ¶ronlarÄ±, Ã¶ÄŸrenme oranÄ±, alpha, aktivasyon ve solver parametrelerini en iyi doÄŸruluk deÄŸerini verecek ÅŸekilde seÃ§er.\n",
        "\n",
        "Best trial Ã§Ä±ktÄ±sÄ±, hem deneme numarasÄ±nÄ± hem de en iyi doÄŸruluk deÄŸerini ve kullanÄ±lan hiperparametreleri gÃ¶sterir.\n",
        "\n",
        "Bu sonuÃ§lar kullanÄ±larak, MLP modeli test setinde optimize edilmiÅŸ hiperparametrelerle yeniden eÄŸitilebilir ve deÄŸerlendirilir.\n"
      ],
      "metadata": {
        "id": "4rjKdRAqZS0D"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "275f04fd"
      },
      "source": [
        "### 9.3 EÄŸitim DÃ¶ngÃ¼sÃ¼\n",
        "\n",
        "Optuna optimizasyon sÃ¼recinde, her bir `trial` (deneme) aslÄ±nda bir `eÄŸitim dÃ¶ngÃ¼sÃ¼`nÃ¼ temsil eder. Bu dÃ¶ngÃ¼, `objective` fonksiyonu iÃ§inde gerÃ§ekleÅŸtirilir. `objective` fonksiyonu, her Ã§aÄŸrÄ±ldÄ±ÄŸÄ±nda aÅŸaÄŸÄ±daki adÄ±mlarÄ± uygular:\n",
        "\n",
        "1.  **Hiperparametre Ã–rneklemesi**: Optuna, tanÄ±mlanan arama uzayÄ±ndan yeni bir hiperparametre kombinasyonu (`n_layers`, `n_units_lX`, `learning_rate_init`, `alpha`, `activation`, `solver`) Ã¶nerir.\n",
        "2.  **Model OluÅŸturma ve EÄŸitim**: Ã–nerilen hiperparametrelerle yeni bir `MLPClassifier` modeli oluÅŸturulur ve bu model, eÄŸitim veri seti (`X_train`, `y_train`) Ã¼zerinde eÄŸitilir.\n",
        "3.  **DoÄŸrulama (Validation) Skoru Hesaplama**: EÄŸitilen model, doÄŸrulama veri seti (`X_val`, `y_val`) Ã¼zerinde tahminler yapar ve bu tahminler kullanÄ±larak modelin performansÄ± (bu durumda `accuracy_score`) hesaplanÄ±r.\n",
        "4.  **Skoru Geri DÃ¶ndÃ¼rme**: Hesaplanan doÄŸrulama skoru, Optuna'ya geri dÃ¶ndÃ¼rÃ¼lÃ¼r. Optuna, bu skoru kullanarak hangi hiperparametre kombinasyonlarÄ±nÄ±n daha iyi performans gÃ¶sterdiÄŸini deÄŸerlendirir ve bir sonraki denemelerde arama stratejisini buna gÃ¶re ayarlar.\n",
        "\n",
        "`study.optimize(objective, n_trials=150)` komutu, bu eÄŸitim dÃ¶ngÃ¼sÃ¼nÃ¼ 150 kez tekrarlayarak en iyi performans gÃ¶steren hiperparametre kombinasyonunu sistematik bir ÅŸekilde arar. Bu sayede, manuel olarak farklÄ± parametre kombinasyonlarÄ±nÄ± denemek yerine, otomatik ve verimli bir arama yapÄ±lÄ±r."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e8I8tl-M5kJ"
      },
      "source": [
        "###9.4 En Ä°yi Trialâ€™Ä±n RaporlanmasÄ±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7ba5718"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import pandas as pd\n",
        "\n",
        "# En iyi deneme parametrelerini al\n",
        "best_params = study.best_trial.params\n",
        "\n",
        "# hidden_layer_sizes parametresini tuple formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r\n",
        "hidden_layer_sizes_list = []\n",
        "for i in range(best_params['n_layers']):\n",
        "    hidden_layer_sizes_list.append(best_params[f'n_units_l{i}'])\n",
        "best_params['hidden_layer_sizes'] = tuple(hidden_layer_sizes_list)\n",
        "\n",
        "# n_layers ve n_units_lX parametrelerini modelden Ã§Ä±kar, Ã§Ã¼nkÃ¼ artÄ±k hidden_layer_sizes'da birleÅŸtirildiler\n",
        "best_params.pop('n_layers')\n",
        "for i in range(len(hidden_layer_sizes_list)):\n",
        "    best_params.pop(f'n_units_l{i}')\n",
        "\n",
        "# En iyi parametrelerle yeni bir MLP modeli oluÅŸtur\n",
        "best_mlp_model_optuna = MLPClassifier(\n",
        "    **best_params,\n",
        "    max_iter=1000, # Optimizasyon objective fonksiyonunda sabit tuttuÄŸumuz deÄŸer\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Optuna tarafÄ±ndan bulunan en iyi parametreler:\")\n",
        "for key, value in study.best_trial.params.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(\"\\nEn iyi model eÄŸiliyor...\")\n",
        "best_mlp_model_optuna.fit(X_train, y_train)\n",
        "\n",
        "# DoÄŸrulama seti Ã¼zerinde tahminler yapalÄ±m\n",
        "y_pred_optuna = best_mlp_model_optuna.predict(X_val)\n",
        "y_proba_optuna = best_mlp_model_optuna.predict_proba(X_val)[:, 1] # ROC-AUC iÃ§in pozitif sÄ±nÄ±f olasÄ±lÄ±klarÄ±\n",
        "\n",
        "# Metrikleri hesaplayalÄ±m\n",
        "accuracy_optuna = accuracy_score(y_val, y_pred_optuna)\n",
        "precision_optuna = precision_score(y_val, y_pred_optuna, zero_division=0)\n",
        "recall_optuna = recall_score(y_val, y_pred_optuna, zero_division=0)\n",
        "f1_optuna = f1_score(y_val, y_pred_optuna, zero_division=0)\n",
        "roc_auc_optuna = roc_auc_score(y_val, y_proba_optuna)\n",
        "\n",
        "# SonuÃ§larÄ± gÃ¶rÃ¼ntÃ¼leyelim\n",
        "print(\"\\n--- Optuna En Ä°yi Model PerformansÄ± (Validation Set) ---\")\n",
        "print(f\"Accuracy:  {accuracy_optuna:.4f}\")\n",
        "print(f\"Precision: {precision_optuna:.4f}\")\n",
        "print(f\"Recall:    {recall_optuna:.4f}\")\n",
        "print(f\"F1-Score:  {f1_optuna:.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc_optuna:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu adÄ±mda, Optuna ile hiperparametre optimizasyonu sonucu bulunan en iyi parametreler kullanÄ±larak MLP modeli yeniden oluÅŸturulmuÅŸ ve doÄŸrulama seti Ã¼zerinde performansÄ± Ã¶lÃ§Ã¼lmÃ¼ÅŸtÃ¼r.\n",
        "\n",
        "1. **En iyi parametrelerin alÄ±nmasÄ± ve dÃ¼zenlenmesi:**\n",
        "\n",
        "best_params = study.best_trial.params\n",
        "\n",
        "//hidden_layer_sizes parametresini tuple formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r\n",
        "\n",
        "\n",
        "hidden_layer_sizes_list = []\n",
        "for i in range(best_params['n_layers']):\n",
        "    hidden_layer_sizes_list.append(best_params[f'n_units_l{i}'])\n",
        "best_params['hidden_layer_sizes'] = tuple(hidden_layer_sizes_list)\n",
        "\n",
        "//n_layers ve n_units_lX parametrelerini modelden Ã§Ä±kar\n",
        "\n",
        "\n",
        "best_params.pop('n_layers')\n",
        "for i in range(len(hidden_layer_sizes_list)):\n",
        "    best_params.pop(f'n_units_l{i}')\n",
        "\n",
        "- Optuna, katman ve nÃ¶ron sayÄ±sÄ±nÄ± ayrÄ± ayrÄ± parametreler olarak verir.\n",
        "\n",
        "- Bu adÄ±mda tÃ¼m katmanlar hidden_layer_sizes tupleâ€™Ä±nda birleÅŸtirilir ve gereksiz parametreler Ã§Ä±karÄ±lÄ±r.\n",
        "\n",
        "2. **En iyi parametrelerle MLP modeli oluÅŸturma ve eÄŸitme:**\n",
        "\n",
        "best_mlp_model_optuna = MLPClassifier(\n",
        "    **best_params,\n",
        "    max_iter=1000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "best_mlp_model_optuna.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "- **best_params ile tÃ¼m optimize edilmiÅŸ parametreler modele aktarÄ±lÄ±r\n",
        "\n",
        "- Model, eÄŸitim setinde fit edilir\n",
        "\n",
        "3. **Validation seti Ã¼zerinde tahmin ve performans hesaplama:**\n",
        "y_pred_optuna = best_mlp_model_optuna.predict(X_val)\n",
        "y_proba_optuna = best_mlp_model_optuna.predict_proba(X_val)[:, 1]\n",
        "- Tahminler yapÄ±lÄ±r ve accuracy, precision, recall, F1-score ve ROC-AUC deÄŸerleri hesaplanÄ±r\n",
        "\n",
        "accuracy_optuna = accuracy_score(y_val, y_pred_optuna)\n",
        "precision_optuna = precision_score(y_val, y_pred_optuna, zero_division=0)\n",
        "recall_optuna = recall_score(y_val, y_pred_optuna, zero_division=0)\n",
        "f1_optuna = f1_score(y_val, y_pred_optuna, zero_division=0)\n",
        "roc_auc_optuna = roc_auc_score(y_val, y_proba_optuna)\n",
        "\n",
        "4- **SonuÃ§larÄ±n gÃ¶rÃ¼ntÃ¼lenmesi:**\n",
        "\n",
        "print(\"\\n--- Optuna En Ä°yi Model PerformansÄ± (Validation Set) ---\")\n",
        "\n",
        "\n",
        "print(f\"Accuracy:  {accuracy_optuna:.4f}\")\n",
        "\n",
        "\n",
        "print(f\"Precision: {precision_optuna:.4f}\")\n",
        "\n",
        "\n",
        "print(f\"Recall:    {recall_optuna:.4f}\")\n",
        "\n",
        "\n",
        "print(f\"F1-Score:  {f1_optuna:.4f}\")\n",
        "\n",
        "\n",
        "print(f\"ROC-AUC:   {roc_auc_optuna:.4f}\")\n",
        "\n",
        "Optuna optimizasyonu sonrasÄ± modelin validation set performansÄ± raporlanÄ±r\n",
        "\n",
        "---\n",
        "Bu adÄ±m, Optunaâ€™nÄ±n Ã¶nerdiÄŸi en iyi hiperparametrelerle modeli oluÅŸturmayÄ± ve performansÄ±nÄ± doÄŸrulamayÄ± amaÃ§lar.\n",
        "\n",
        "\n",
        "Validation seti performansÄ±, hiperparametre optimizasyonunun ne kadar baÅŸarÄ±lÄ± olduÄŸunu gÃ¶sterir ve ilerleyen adÄ±mda test seti Ã¼zerinde nihai deÄŸerlendirme yapÄ±labilir.\n",
        "\n"
      ],
      "metadata": {
        "id": "_5Clf21baFuW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfoVb-6OPT9t"
      },
      "source": [
        "###10. XAI â€“ SHAP AÃ§Ä±klanabilirlik Analizi (Zorunlu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "594a1f23"
      },
      "outputs": [],
      "source": [
        "# SHAP kÃ¼tÃ¼phanesini yÃ¼kle\n",
        "!pip install shap"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu adÄ±mda, model aÃ§Ä±klanabilirliÄŸi iÃ§in kullanÄ±lacak SHAP (SHapley Additive exPlanations) kÃ¼tÃ¼phanesi yÃ¼klenmektedir."
      ],
      "metadata": {
        "id": "zBoGm5YhbMfM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ecc1bf1"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# En iyi modeli seÃ§in (Optuna ile bulunan en iyi model)\n",
        "# best_mlp_model_optuna Ã¶nceki adÄ±mlarda tanÄ±mlanmÄ±ÅŸ olmalÄ±\n",
        "best_model = best_mlp_model_optuna\n",
        "\n",
        "# SHAP Explainer oluÅŸtur\n",
        "# MLPClassifier bir nÃ¶ral aÄŸ olduÄŸu iÃ§in DeepExplainer daha uygundur.\n",
        "# Arka plan verisi olarak eÄŸitim setinin bir alt kÃ¼mesini kullanmak iyi bir yaklaÅŸÄ±mdÄ±r.\n",
        "# Ancak, DeepExplainer iÃ§in modelin TensorFlow/Keras ile oluÅŸturulmuÅŸ olmasÄ± beklenir.\n",
        "# sklearn MLPClassifier iÃ§in KernelExplainer kullanmak daha genel ve uygun olabilir.\n",
        "# KernelExplainer iÃ§in daha kÃ¼Ã§Ã¼k bir Ã¶rneklem seÃ§mek hesaplama sÃ¼resini azaltÄ±r.\n",
        "\n",
        "# KernelExplainer iÃ§in arka plan verisi (eÄŸitim setinden rastgele 100 Ã¶rnek)\n",
        "explainer = shap.KernelExplainer(best_model.predict_proba, X_train[np.random.choice(X_train.shape[0], 100, replace=False)])\n",
        "\n",
        "# Test seti Ã¼zerinde SHAP deÄŸerlerini hesapla\n",
        "# TÃ¼m test seti iÃ§in hesaplamak uzun sÃ¼rebilir, Ã¶rneklem alabiliriz.\n",
        "# shap_values = explainer.shap_values(X_test)\n",
        "# Hesaplama sÃ¼resini kÄ±saltmak iÃ§in X_test'in bir alt kÃ¼mesini kullanalÄ±m (Ã¶rneÄŸin ilk 50 Ã¶rnek)\n",
        "shap_values = explainer.shap_values(X_test[:50])\n",
        "\n",
        "print(\"SHAP Explainer oluÅŸturuldu ve SHAP deÄŸeleri hesaplandÄ±.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KernelExplainer, sklearn MLPClassifier gibi scikit-learn modelleri iÃ§in uygundur.\n",
        "\n",
        "Arka plan verisi olarak eÄŸitim setinden rastgele bir alt kÃ¼me seÃ§ilmiÅŸtir (hesaplama sÃ¼resini azaltmak iÃ§in).\n",
        "\n",
        "SHAP deÄŸerleri, modelin tahminine her bir Ã¶zelliÄŸin katkÄ±sÄ±nÄ± gÃ¶sterir.\n",
        "\n",
        "Test setinin tamamÄ± yerine kÃ¼Ã§Ã¼k bir Ã¶rneklem kullanÄ±lmÄ±ÅŸtÄ±r; bÃ¼yÃ¼k veri setlerinde bu iÅŸlem uzun sÃ¼rebilir."
      ],
      "metadata": {
        "id": "n-c2hFDQbXKF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f994a545"
      },
      "source": [
        "### 10.1.1 SHAP Summary Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0310c6d"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract SHAP values for Class 1 (Benign) and create a shap.Explanation object\n",
        "# shap_values from KernelExplainer with predict_proba often returns (samples, features, classes)\n",
        "shap_values_class1 = shap_values[:, :, 1]\n",
        "\n",
        "# Create a shap.Explanation object for class 1\n",
        "explanation_class1 = shap.Explanation(values=shap_values_class1,\n",
        "                                     base_values=explainer.expected_value[1],\n",
        "                                     data=X_test[:50],\n",
        "                                     feature_names=X.columns.tolist())\n",
        "\n",
        "# SHAP summary_plot (Ã¶zelliklerin genel etkisini gÃ¶sterir)\n",
        "shap.summary_plot(explanation_class1, show=False)\n",
        "plt.title('SHAP Summary Plot for MLP Model (Class 1 - Benign)')\n",
        "plt.show()\n",
        "\n",
        "print(\"SHAP summary_plot oluÅŸturuldu.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu adÄ±mda, MLP modelinin Class 1 (Benign) tahminleri iÃ§in SHAP deÄŸerleri kullanÄ±larak Ã¶zet bir gÃ¶rselleÅŸtirme yapÄ±lmÄ±ÅŸtÄ±r.\n",
        "\n",
        "SHAP Summary Plot, her bir Ã¶zelliÄŸin modelin tahminine ne kadar katkÄ±da bulunduÄŸunu gÃ¶sterir.\n",
        "\n",
        "Renkler, Ã¶zelliÄŸin deÄŸerini temsil eder (yÃ¼ksek/low deÄŸerler).\n",
        "\n",
        "Grafik, Ã¶zellikle hangi Ã¶zelliklerin Benign sÄ±nÄ±fÄ±nÄ± tahmin etmede daha etkili olduÄŸunu hÄ±zlÄ±ca gÃ¶rmemizi saÄŸlar.\n",
        "\n",
        "shap.Explanation objesi, SHAP deÄŸerlerini, temel deÄŸerleri ve ilgili veri ile birleÅŸtirir, gÃ¶rselleÅŸtirme iÃ§in gereklidir.\n",
        "\n",
        "Bu plot sayesinde modelin karar mekanizmasÄ± daha anlaÅŸÄ±lÄ±r hale gelir ve feature importance deÄŸerleri yorumlanabilir."
      ],
      "metadata": {
        "id": "ecU1Xg7bbe2W"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d6b7314"
      },
      "source": [
        "### 10.1.2 SHAP Bar Plot (Feature Importance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2a1c0714"
      },
      "outputs": [],
      "source": [
        "# SHAP bar_plot (Ã¶zellik Ã¶nem sÄ±rasÄ±nÄ± gÃ¶sterir)\n",
        "shap.plots.bar(explanation_class1, show=False)\n",
        "plt.title('SHAP Feature Importance Bar Plot (Class 1 - Benign)')\n",
        "plt.show()\n",
        "\n",
        "print(\"SHAP bar_plot (feature importance) Ã§izdirildi.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu adÄ±mda, MLP modelinin Class 1 (Benign) tahminleri iÃ§in SHAP deÄŸerleri kullanÄ±larak, Ã¶zelliklerin Ã¶nem sÄ±rasÄ± gÃ¶rselleÅŸtirilmiÅŸtir.\n",
        "\n",
        "Bar Plot, modelin tahminlerine en Ã§ok katkÄ±da bulunan Ã¶zellikleri azalan Ã¶neme gÃ¶re gÃ¶sterir.\n",
        "\n",
        "Uzun barlar, o Ã¶zelliÄŸin model tahmininde daha yÃ¼ksek etkisi olduÄŸunu gÃ¶sterir.\n",
        "\n",
        "Bu grafik, Ã¶zellikle feature selection ve model yorumlanabilirliÄŸi iÃ§in kullanÄ±ÅŸlÄ±dÄ±r.\n",
        "\n",
        "Class 1 (Benign) odaklÄ± olduÄŸu iÃ§in, sadece bu sÄ±nÄ±fÄ±n tahmininde hangi Ã¶zelliklerin kritik olduÄŸu Ã¶ne Ã§Ä±karÄ±lmÄ±ÅŸtÄ±r.\n",
        "\n",
        "Bu plot ile modelin hangi Ã¶zelliklere dayalÄ± karar verdiÄŸi hÄ±zlÄ±ca anlaÅŸÄ±labilir ve gÃ¶rselleÅŸtirilmiÅŸ bir feature importance tablosu elde edilir.\n"
      ],
      "metadata": {
        "id": "TgJ5HRrHbrLE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d8a0192"
      },
      "source": [
        "### 10.1.3 En BaskÄ±n Ã–zelliklerin YorumlanmasÄ± ve Model PerformansÄ± Ä°liÅŸkisi\n",
        "\n",
        "SHAP (SHapley Additive exPlanations) deÄŸerleri, bir modelin tahminlerinin tek tek Ã¶zellikler tarafÄ±ndan nasÄ±l etkilendiÄŸini aÃ§Ä±klayan bir oyun teorisi yaklaÅŸÄ±mÄ±dÄ±r. Her bir SHAP deÄŸeri, bir Ã¶zelliÄŸin bir tahmin Ã¼zerindeki katkÄ±sÄ±nÄ± gÃ¶sterir.\n",
        "\n",
        "**SHAP Summary Plot Yorumu:**\n",
        "*   `summary_plot`, her bir Ã¶zellik iÃ§in SHAP deÄŸerlerinin daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶sterir. Her bir nokta, bir gÃ¶zlem iÃ§in bir Ã¶zelliÄŸin SHAP deÄŸerini temsil eder.\n",
        "*   Renkler, Ã¶zelliÄŸin orijinal deÄŸerini gÃ¶sterir (kÄ±rmÄ±zÄ± yÃ¼ksek, mavi dÃ¼ÅŸÃ¼k).\n",
        "*   Y ekseni, Ã¶zelliklerin genel Ã¶nemine gÃ¶re sÄ±ralanmÄ±ÅŸtÄ±r.\n",
        "*   Ã–rneÄŸin, bir Ã¶zelliÄŸin yÃ¼ksek deÄŸeri (kÄ±rmÄ±zÄ±) pozitif bir SHAP deÄŸerine sahipse, bu Ã¶zelliÄŸin yÃ¼ksek deÄŸerlerinin modelin tahminini artÄ±rdÄ±ÄŸÄ± (burada 'Benign' sÄ±nÄ±fÄ±na doÄŸru yÃ¶nlendirdiÄŸi) anlamÄ±na gelir.\n",
        "*   EÄŸer bir Ã¶zelliÄŸin dÃ¼ÅŸÃ¼k deÄŸeri (mavi) negatif bir SHAP deÄŸerine sahipse, bu Ã¶zelliÄŸin dÃ¼ÅŸÃ¼k deÄŸerlerinin modelin tahminini azalttÄ±ÄŸÄ± (burada 'Malign' sÄ±nÄ±fÄ±na doÄŸru yÃ¶nlendirdiÄŸi) anlamÄ±na gelir.\n",
        "\n",
        "**SHAP Bar Plot Yorumu (Feature Importance):**\n",
        "*   `bar_plot`, Ã¶zelliklerin ortalama mutlak SHAP deÄŸerlerini gÃ¶stererek genel Ã¶zellik Ã¶nemini sÄ±ralar.\n",
        "*   Ã‡ubuk ne kadar uzunsa, Ã¶zellik modelin tahminleri Ã¼zerinde o kadar etkilidir.\n",
        "\n",
        "**En BaskÄ±n Ã–zellikler ve Yorumu:**\n",
        "\n",
        "(YukarÄ±daki grafikler oluÅŸtuktan sonra bu kÄ±sÄ±m doldurulacaktÄ±r. Ancak genel olarak, meme kanseri veri setinde 'mean radius', 'worst perimeter', 'mean concave points' gibi tÃ¼mÃ¶rÃ¼n boyutu, ÅŸekli ve agresifliÄŸini gÃ¶steren Ã¶zelliklerin yÃ¼ksek SHAP deÄŸerlerine sahip olmasÄ± beklenir.)\n",
        "\n",
        "*   **Ã–rnek (Grafiklere gÃ¶re yorumlanacaktÄ±r):**\n",
        "    *   `worst perimeter`: Muhtemelen en Ã¶nemli Ã¶zelliklerden biri olacaktÄ±r. YÃ¼ksek deÄŸerlerinin 'Malign' sÄ±nÄ±fÄ±na doÄŸru gÃ¼Ã§lÃ¼ bir ÅŸekilde etki etmesi (veya 'Benign' sÄ±nÄ±fÄ±ndan uzaklaÅŸtÄ±rmasÄ±) beklenir.\n",
        "    *   `mean radius`: Benzer ÅŸekilde, tÃ¼mÃ¶rÃ¼n ortalama yarÄ±Ã§apÄ± da Ã¶nemli bir belirleyici olacaktÄ±r.\n",
        "    *   `mean concave points`: TÃ¼mÃ¶rÃ¼n iÃ§bÃ¼key noktalarÄ±, hÃ¼crelerin dÃ¼zensizliÄŸini yansÄ±ttÄ±ÄŸÄ± iÃ§in sÄ±nÄ±flandÄ±rmada kritik rol oynar.\n",
        "\n",
        "**Model PerformansÄ± ve SHAP Ã–nem SÄ±ralamasÄ± ArasÄ±ndaki Ä°liÅŸki:**\n",
        "\n",
        "Modelinizin doÄŸrulama setinde %100'lÃ¼k mÃ¼kemmel bir performans sergilemesi, modelin bu veri setindeki ayÄ±rÄ±cÄ± Ã¶zellikleri Ã§ok iyi Ã¶ÄŸrendiÄŸini gÃ¶sterir. SHAP analizi, modelin bu yÃ¼ksek performansÄ± elde ederken hangi Ã¶zelliklere ne kadar gÃ¼vendiÄŸini ve bu Ã¶zelliklerin tahminleri nasÄ±l etkilediÄŸini somutlaÅŸtÄ±rÄ±r.\n",
        "\n",
        "*   **TutarlÄ±lÄ±k:** EÄŸer SHAP analizinde ortaya Ã§Ä±kan en Ã¶nemli Ã¶zellikler, alan bilgisi (meme kanseri biyolojisi) ile tutarlÄ±ysa (Ã¶rneÄŸin, bÃ¼yÃ¼k ve dÃ¼zensiz tÃ¼mÃ¶rlerin malign olma eÄŸiliminde olmasÄ±), bu modelin sadece doÄŸru tahmin yapmakla kalmayÄ±p, aynÄ± zamanda biyolojik olarak anlamlÄ± desenleri de yakaladÄ±ÄŸÄ±nÄ± gÃ¶sterir.\n",
        "*   **GÃ¼venilirlik:** SHAP deÄŸerleri, modelin neden belirli bir sÄ±nÄ±flandÄ±rma yaptÄ±ÄŸÄ±nÄ± 'gÃ¶rselleÅŸtirdiÄŸi' iÃ§in, modelin yÃ¼ksek performansÄ±na olan gÃ¼veni artÄ±rÄ±r. Modelin 'karakutusu' biraz daha ÅŸeffaf hale gelir.\n",
        "*   **Potansiyel AÅŸÄ±rÄ± Uyum (Overfitting) Ä°puÃ§larÄ±:** EÄŸer model Ã§ok yÃ¼ksek performansa sahipken, SHAP analizi anlamsÄ±z veya beklemeyen Ã¶zelliklerin Ã§ok baskÄ±n olduÄŸunu gÃ¶sterirse, bu durum modelin veri setindeki gÃ¼rÃ¼ltÃ¼yÃ¼ veya tesadÃ¼fi korelasyonlarÄ± ezberlemiÅŸ olabileceÄŸi, yani aÅŸÄ±rÄ± uyum belirtisi olabileceÄŸi konusunda ipuÃ§larÄ± verebilir. Ancak, bu veri setinde %100 doÄŸruluk biyolojik olarak anlamlÄ± Ã¶zelliklerle desteklenirse, bu durum modelin oldukÃ§a robust olduÄŸunu gÃ¶sterir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77aa4bb8"
      },
      "source": [
        "### 10.2.3 SHAP Force Plot (Tek Bir Ã–rnek Ä°Ã§in Karar AÃ§Ä±klamasÄ±)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7b68dbdf"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Tek bir Ã¶rnek iÃ§in SHAP force_plot Ã§izimi\n",
        "# Ã–rneÄŸin, test setindeki ilk Ã¶rneÄŸi seÃ§elim (index 0)\n",
        "# explanation_class1 nesnesini kullanarak, belirli bir Ã¶rneÄŸin SHAP deÄŸerlerini alÄ±yoruz\n",
        "shap.plots.force(explanation_class1[0], matplotlib=True, show=False)\n",
        "plt.title('SHAP Force Plot for a Single Instance (Class 1 - Benign)')\n",
        "plt.show()\n",
        "\n",
        "print(\"SHAP force_plot oluÅŸturuldu.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu adÄ±mda, MLP modelinin Class 1 (Benign) tahmini iÃ§in tek bir test Ã¶rneÄŸi Ã¼zerinde SHAP deÄŸerleri kullanÄ±larak modelin karar mekanizmasÄ± gÃ¶rselleÅŸtirilmiÅŸtir.\n",
        "\n",
        "Force Plot, bir Ã¶rneÄŸin tahminine hangi Ã¶zelliklerin pozitif veya negatif katkÄ± saÄŸladÄ±ÄŸÄ±nÄ± gÃ¶rselleÅŸtirir.\n",
        "\n",
        "SaÄŸ tarafa iten deÄŸerler, sÄ±nÄ±f olasÄ±lÄ±ÄŸÄ±nÄ± arttÄ±rÄ±r; sol tarafa iten deÄŸerler ise olasÄ±lÄ±ÄŸÄ± azaltÄ±r.\n",
        "\n",
        "Bu grafik, modelin bireysel tahminlerinin nedenlerini anlamak iÃ§in kullanÄ±lÄ±r.\n",
        "\n",
        "Class 1 (Benign) iÃ§in, Ã¶zelliklerin tahmin Ã¼zerindeki etkisi aÃ§Ä±kÃ§a gÃ¶rÃ¼lebilir, bÃ¶ylece modelin karar mekanizmasÄ± detaylÄ± ÅŸekilde yorumlanabilir.\n",
        "\n",
        "Force plot, Ã¶zellikle bireysel tahminlerin aÃ§Ä±klanabilirliÄŸini gÃ¶stermek ve modelin gÃ¼venilirliÄŸini artÄ±rmak iÃ§in gÃ¼Ã§lÃ¼ bir araÃ§tÄ±r."
      ],
      "metadata": {
        "id": "m7FfL6RmfM-P"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8632a10c"
      },
      "source": [
        "### 10.2.4 SHAP Decision Plot (Karar Yolunun Ã–zellere GÃ¶re KatkÄ±sÄ±)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b83d0da4"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# SHAP decision_plot Ã§izimi\n",
        "# explanation_class1 nesnesi, zaten aÃ§Ä±klanmak istenen sÄ±nÄ±f (Class 1 - Benign) iÃ§in hazÄ±rlandÄ±.\n",
        "# Ä°lk 5 Ã¶rneÄŸi gÃ¶rselleÅŸtirmek iÃ§in bir alt kÃ¼me seÃ§ebiliriz\n",
        "\n",
        "shap.decision_plot(\n",
        "    explainer.expected_value[1], # Base value\n",
        "    explanation_class1.values[:5], # Ä°lk 5 Ã¶rneÄŸin SHAP deÄŸerleri\n",
        "    explanation_class1.data[:5], # Ä°lk 5 Ã¶rneÄŸin gerÃ§ek verileri\n",
        "    feature_names=X.columns.tolist(), # Ã–zellik isimleri\n",
        "    show=False,\n",
        "    title='SHAP Decision Plot for Selected Instances (Class 1 - Benign)'\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "print(\"SHAP decision_plot oluÅŸturuldu.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu adÄ±mda, MLP modelinin Class 1 (Benign) tahminleri iÃ§in seÃ§ilmiÅŸ Ã¶rnekler Ã¼zerinde SHAP deÄŸerleri ile karar mekanizmasÄ± gÃ¶rselleÅŸtirilmiÅŸtir.\n",
        "\n",
        "Decision Plot, birden fazla Ã¶rneÄŸin tahmin sÃ¼recini Ã¶zellik katkÄ±larÄ± Ã¼zerinden adÄ±m adÄ±m gÃ¶sterir.\n",
        "\n",
        "Base value: Modelin tahmin Ã¶ncesi ortalama beklentisi.\n",
        "\n",
        "SHAP deÄŸerleri: Her bir Ã¶zelliÄŸin tahmin Ã¼zerindeki pozitif veya negatif etkisi.\n",
        "\n",
        "Ã‡izim, Ã¶rneklerin karar sÃ¼recini karÅŸÄ±laÅŸtÄ±rmayÄ± ve hangi Ã¶zelliklerin tahminleri nasÄ±l etkilediÄŸini hÄ±zlÄ±ca gÃ¶rmeyi saÄŸlar.\n",
        "\n",
        "Ã–zellikle bireysel ve kÃ¼Ã§Ã¼k grup tahminleri iÃ§in modelin mantÄ±ÄŸÄ±nÄ± gÃ¶rselleÅŸtirmek amacÄ±yla kullanÄ±ÅŸlÄ±dÄ±r.\n",
        "\n",
        "Bu plot ile modelin birden fazla Ã¶rnek Ã¼zerindeki karar mantÄ±ÄŸÄ± detaylÄ± ÅŸekilde analiz edilebilir ve Ã¶zelliklerin katkÄ±larÄ± net bir ÅŸekilde anlaÅŸÄ±labilir."
      ],
      "metadata": {
        "id": "pQJKwnMQfYCS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2f410e7"
      },
      "source": [
        "# KapanÄ±ÅŸ Raporu Ã–zeti\n",
        "\n",
        "Bu rapor, Meme Kanseri veri setini kullanarak Ã‡ok KatmanlÄ± AlgÄ±layÄ±cÄ± (MLP) modellerinin geliÅŸtirilmesi, optimize edilmesi ve yorumlanmasÄ± sÃ¼recini Ã¶zetlemektedir. Proje, veri Ã¶n iÅŸleme, keÅŸifsel veri analizi (EDA), model eÄŸitimi, hiperparametre optimizasyonu ve aÃ§Ä±klanabilirlik analizi (XAI) aÅŸamalarÄ±nÄ± kapsamaktadÄ±r.\n",
        "\n",
        "## 1. Veri YÃ¼kleme ve Ã–n Ä°ÅŸleme\n",
        "\n",
        "*   **Veri Seti KaynaÄŸÄ±**: Proje, `sklearn.datasets` kÃ¼tÃ¼phanesinden yÃ¼klenen Breast Cancer (Meme Kanseri) veri setini kullanmÄ±ÅŸtÄ±r. Bu veri seti, tÃ¼mÃ¶r hÃ¼crelerinin Ã§eÅŸitli Ã¶zelliklerine dayanarak tÃ¼mÃ¶rÃ¼n malign (kÃ¶tÃ¼ huylu) veya benign (iyi huylu) olup olmadÄ±ÄŸÄ±nÄ± sÄ±nÄ±flandÄ±rmayÄ± amaÃ§layan 569 Ã¶rnek ve 30 Ã¶zellik iÃ§ermektedir.\n",
        "*   **Eksik DeÄŸer KontrolÃ¼**: Veri setinde hiÃ§bir eksik deÄŸere rastlanmamÄ±ÅŸtÄ±r. Bu, veri temizleme aÅŸamasÄ±nÄ± Ã¶nemli Ã¶lÃ§Ã¼de basitleÅŸtirmiÅŸtir.\n",
        "*   **AykÄ±rÄ± DeÄŸer Analizi (IQR, Z-Skor, Boxplot)**: Veri setinde IQR ve Z-Skor yÃ¶ntemleriyle aykÄ±rÄ± deÄŸerler tespit edilmiÅŸtir. Ã–zellikle `area error`, `radius error`, `perimeter error` ve `worst area` gibi Ã¶zelliklerde yÃ¼ksek sayÄ±da aykÄ±rÄ± deÄŸer bulunmuÅŸtur. `worst concave points` Ã¶zelliÄŸi ise hiÃ§bir aykÄ±rÄ± deÄŸer iÃ§ermemektedir. Boxplot'lar, bu aykÄ±rÄ± deÄŸerlerin daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶rsel olarak doÄŸrulamÄ±ÅŸtÄ±r ve tÃ¼mÃ¶rÃ¼n boyutu ve ÅŸekliyle ilgili Ã¶zelliklerde yoÄŸun aykÄ±rÄ± deÄŸer kÃ¼meleri gÃ¶zlemlenmiÅŸtir. Bu durum, veri setinde biyolojik olarak sÄ±ra dÄ±ÅŸÄ± ancak Ã¶nemli vakalarÄ±n bulunduÄŸunu gÃ¶stermektedir.\n",
        "*   **Veri Tipleri**: TÃ¼m Ã¶zellikler sayÄ±sal (`float64`), hedef deÄŸiÅŸken (`target`) ise `int64` (0 ve 1) tipindedir. Bu, veri setinin homojen bir yapÄ±ya sahip olduÄŸunu ve ek tip dÃ¶nÃ¼ÅŸÃ¼mlerine gerek kalmadÄ±ÄŸÄ±nÄ± gÃ¶stermiÅŸtir.\n",
        "\n",
        "## 2. KeÅŸifsel Veri Analizi (EDA)\n",
        "\n",
        "*   **Ä°statistiksel Bulgular (`df.describe()`)**: `df.describe()` Ã§Ä±ktÄ±sÄ±, her bir Ã¶zelliÄŸin ortalama, standart sapma, minimum, maksimum ve Ã§eyreklik (Q1, Q2, Q3) deÄŸerlerini sunmuÅŸtur. Bu istatistikler, Ã¶zelliklerin daÄŸÄ±lÄ±mÄ± ve varyasyonu hakkÄ±nda ilk derinlemesine bilgiyi saÄŸlamÄ±ÅŸtÄ±r. Ã–zellikle tÃ¼mÃ¶r boyutuyla ilgili Ã¶zelliklerin (Ã¶rn. `mean radius`, `mean area`) geniÅŸ deÄŸer aralÄ±klarÄ±na sahip olduÄŸu gÃ¶rÃ¼lmÃ¼ÅŸtÃ¼r.\n",
        "*   **Pearson Korelasyon Matrisi ve Heatmap**: Korelasyon analizi, Ã¶zellikler arasÄ±nda gÃ¼Ã§lÃ¼ doÄŸrusal iliÅŸkilerin varlÄ±ÄŸÄ±nÄ± ortaya koymuÅŸtur.\n",
        "    *   **YÃ¼ksek Korelasyonlu Ã‡iftler (Multikolinearite Potansiyeli)**: `mean radius` ile `mean perimeter` (0.997855), `worst perimeter` ile `worst radius` (0.993708) ve `mean radius` ile `mean area` (0.987357) gibi tÃ¼mÃ¶rÃ¼n fiziksel boyutlarÄ±nÄ± temsil eden Ã¶zellikler arasÄ±nda Ã§ok yÃ¼ksek pozitif korelasyonlar gÃ¶zlemlenmiÅŸtir. Bu, multikolinearite potansiyeline iÅŸaret eder ve doÄŸrusal modellere dayalÄ± algoritmalar iÃ§in Ã¶zellik seÃ§imi veya boyut indirgeme ihtiyacÄ±nÄ± dÃ¼ÅŸÃ¼ndÃ¼rmÃ¼ÅŸtÃ¼r.\n",
        "    *   **Hedef DeÄŸiÅŸkenle Ä°liÅŸkiler**: BirÃ§ok tÃ¼mÃ¶r Ã¶zelliÄŸi (`mean radius`, `mean perimeter`, `mean area`, `mean concave points`, `worst radius`, `worst perimeter`, `worst area` vb.) ile `target` arasÄ±nda gÃ¼Ã§lÃ¼ negatif korelasyonlar (-0.730029 gibi) bulunmuÅŸtur. Bu, tÃ¼mÃ¶r boyutunun ve agresif Ã¶zelliklerin artmasÄ±yla tÃ¼mÃ¶rÃ¼n malign olma olasÄ±lÄ±ÄŸÄ±nÄ±n yÃ¼kseldiÄŸini gÃ¶stermiÅŸtir.\n",
        "\n",
        "## 3. Veri Ã–lÃ§eklendirme\n",
        "\n",
        "*   **`StandardScaler` KullanÄ±mÄ±**: `StandardScaler`, Ã¶zelliklerin ortalamasÄ±nÄ± 0 ve standart sapmasÄ±nÄ± 1 olacak ÅŸekilde dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in kullanÄ±lmÄ±ÅŸtÄ±r. Bu Ã¶lÃ§eklendirme, Ã¶zellikle mesafe tabanlÄ± algoritmalar (KNN, SVM) ve gradyan iniÅŸi kullanan algoritmalar (MLP) iÃ§in kritik Ã¶neme sahiptir, zira bu algoritmalar Ã¶lÃ§eklenmemiÅŸ verilerde daha bÃ¼yÃ¼k aralÄ±ÄŸa sahip Ã¶zelliklerden daha fazla etkilenebilir.\n",
        "\n",
        "## 4. Veri BÃ¶lme\n",
        "\n",
        "*   **BÃ¶lÃ¼nme Stratejisi**: Veri seti %70 eÄŸitim, %10 doÄŸrulama ve %20 test oranlarÄ±na gÃ¶re iki aÅŸamalÄ± `train_test_split` ile bÃ¶lÃ¼nmÃ¼ÅŸtÃ¼r.\n",
        "    *   `random_state=42` kullanÄ±larak sonuÃ§larÄ±n tekrar Ã¼retilebilirliÄŸi saÄŸlanmÄ±ÅŸtÄ±r.\n",
        "    *   `stratify=y` parametresi sayesinde, eÄŸitim, doÄŸrulama ve test setlerindeki hedef sÄ±nÄ±f oranlarÄ± orijinal veri setiyle aynÄ± kalmÄ±ÅŸtÄ±r. Bu, hedef deÄŸiÅŸken dengesiz olduÄŸunda modelin her sÄ±nÄ±ftan yeterli Ã¶rnekle Ã¶ÄŸrenmesini ve performans deÄŸerlendirmesinin gÃ¼venilir olmasÄ±nÄ± garanti eder.\n",
        "\n",
        "## 5. MLP Model OluÅŸturma\n",
        "\n",
        "FarklÄ± mimarilere ve hiperparametrelere sahip beÅŸ adet Ã‡ok KatmanlÄ± AlgÄ±layÄ±cÄ± (MLP) modeli oluÅŸturulmuÅŸtur:\n",
        "\n",
        "*   **Model 1 (Basit)**: `hidden_layer_sizes=(16,)`, `activation=\"relu\"`, `learning_rate_init=0.001`\n",
        "*   **Model 2 (Orta)**: `hidden_layer_sizes=(32, 16)`, `activation=\"relu\"`, `learning_rate_init=0.005`\n",
        "*   **Model 3 (GeniÅŸ)**: `hidden_layer_sizes=(64, 64)`, `activation=\"tanh\"`, `learning_rate_init=0.001`\n",
        "*   **Model 4 (Derin)**: `hidden_layer_sizes=(128, 64, 32)`, `activation=\"relu\"`, `learning_rate_init=0.0005`\n",
        "*   **Model 5 (DÃ¼ÅŸÃ¼k Ã–ÄŸrenme OranlÄ±)**: `hidden_layer_sizes=(32,)`, `activation=\"relu\"`, `learning_rate_init=0.0001`\n",
        "\n",
        "Her model, sinir aÄŸÄ± mimarisi, aktivasyon fonksiyonu ve Ã¶ÄŸrenme oranÄ± gibi kritik hiperparametrelerde farklÄ±lÄ±k gÃ¶stermektedir. TÃ¼m modeller `max_iter=1000` ve `random_state=42` ile eÄŸitilmiÅŸtir.\n",
        "\n",
        "## 6. DoÄŸrulama PerformansÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±\n",
        "\n",
        "MLP modellerinin doÄŸrulama seti Ã¼zerindeki performans metrikleri aÅŸaÄŸÄ±daki gibidir:\n",
        "\n",
        "| Model                          | Accuracy | Precision | Recall   | F1-Score | ROC-AUC  |\n",
        "|:-------------------------------|:---------|:----------|:---------|:---------|:---------|\n",
        "| Model 1 (Basit)                | 1.000000 | 1.000000  | 1.000000 | 1.000000 | 1.000000 |\n",
        "| Model 2 (Orta)                 | 0.982143 | 1.000000  | 0.971429 | 0.985507 | 0.998639 |\n",
        "| Model 3 (GeniÅŸ)                | 0.964286 | 0.971429  | 0.971429 | 0.971429 | 0.998639 |\n",
        "| Model 4 (Derin)                | 0.982143 | 1.000000  | 0.971429 | 0.985507 | 1.000000 |\n",
        "| Model 5 (DÃ¼ÅŸÃ¼k Ã–ÄŸrenme OranlÄ±) | 1.000000 | 1.000000  | 1.000000 | 1.000000 | 1.000000 |\n",
        "\n",
        "**Bulgular**: Model 1 (Basit) ve Model 5 (DÃ¼ÅŸÃ¼k Ã–ÄŸrenme OranlÄ±), doÄŸrulama setinde tÃ¼m metriklerde (%100) mÃ¼kemmel performans gÃ¶stermiÅŸtir. Bu, veri setinin nispeten iyi ayrÄ±labilir olduÄŸunu veya basit modellerin bile bu gÃ¶rev iÃ§in yeterli olduÄŸunu dÃ¼ÅŸÃ¼ndÃ¼rmektedir. Bu sonuÃ§lara dayanarak, manuel olarak oluÅŸturulan modeller arasÄ±nda Model 1 veya Model 5'ten herhangi biri en iyi model olarak seÃ§ilebilir.\n",
        "\n",
        "## 7. En Ä°yi Modelin Test Seti Ãœzerindeki DeÄŸerlendirilmesi\n",
        "\n",
        "DoÄŸrulama setindeki mÃ¼kemmel performansÄ±na dayanarak **Model 1 (Basit)** en iyi model olarak seÃ§ilmiÅŸ ve test seti Ã¼zerinde deÄŸerlendirilmiÅŸtir.\n",
        "\n",
        "*   **Performans Metrikleri (Test Seti)**:\n",
        "    *   **Accuracy**: 0.9652\n",
        "    *   **Precision**: 0.9857\n",
        "    *   **Recall**: 0.9583\n",
        "    *   **F1-Score**: 0.9718\n",
        "    *   **ROC-AUC**: 0.9929\n",
        "\n",
        "*   **KarÄ±ÅŸÄ±klÄ±k Matrisi**: Test setinde 42 DoÄŸru Negatif (TN), 69 DoÄŸru Pozitif (TP), 1 YanlÄ±ÅŸ Pozitif (FP) ve 3 YanlÄ±ÅŸ Negatif (FN) gÃ¶zlemlenmiÅŸtir. Bu, modelin malign vakalarÄ± (sÄ±nÄ±f 0) kaÃ§Ä±rmaktan ziyade, benign vakalarÄ± (sÄ±nÄ±f 1) doÄŸru tahmin etmede biraz daha baÅŸarÄ±lÄ± olduÄŸunu gÃ¶sterir (dÃ¼ÅŸÃ¼k FN, yÃ¼ksek TP).\n",
        "\n",
        "*   **ROC EÄŸrisi ve AUC DeÄŸeri**: Test setindeki AUC deÄŸeri 0.9929'dur. Bu, modelin farklÄ± sÄ±nÄ±flandÄ±rma eÅŸiklerinde pozitif ve negatif sÄ±nÄ±flarÄ± Ã§ok iyi ayÄ±rabildiÄŸini gÃ¶stermektedir. EÄŸri, rastgele sÄ±nÄ±flandÄ±rÄ±cÄ±ya gÃ¶re sol Ã¼st kÃ¶ÅŸeye oldukÃ§a yakÄ±ndÄ±r, bu da gÃ¼Ã§lÃ¼ bir model performansÄ±nÄ± teyit eder.\n",
        "\n",
        "## 8. Optuna Hiperparametre Optimizasyonu SonuÃ§larÄ±\n",
        "\n",
        "Optuna, 150 deneme sonucunda doÄŸrulama setinde %100 doÄŸruluk saÄŸlayan en iyi hiperparametre kombinasyonunu bulmuÅŸtur:\n",
        "\n",
        "*   **Katman SayÄ±sÄ± (`n_layers`)**: 1\n",
        "*   **Gizli Katman BoyutlarÄ± (`hidden_layer_sizes`)**: (210,)\n",
        "*   **BaÅŸlangÄ±Ã§ Ã–ÄŸrenme OranÄ± (`learning_rate_init`)**: 0.0002188\n",
        "*   **L2 DÃ¼zenlileÅŸtirme Parametresi (`alpha`)**: 0.0005967\n",
        "*   **Aktivasyon Fonksiyonu (`activation`)**: `'relu'`\n",
        "*   **Optimizer (`solver`)**: `'sgd'`\n",
        "\n",
        "Optuna, 150 deneme sonucunda tek bir gizli katmana ve 210 nÃ¶rona sahip bir modelin en iyi performansÄ± gÃ¶sterdiÄŸini bulmuÅŸtur. DoÄŸrulama setinde %100 doÄŸruluk elde edilmesi, modelin doÄŸrulama verilerini Ã§ok iyi Ã¶ÄŸrendiÄŸini gÃ¶stermektedir. Ancak, bu durum potansiyel bir aÅŸÄ±rÄ± uyum (overfitting) riskine iÅŸaret edebilir; bu nedenle modelin genellenebilirliÄŸi iÃ§in test seti Ã¼zerindeki performansÄ± kritik Ã¶neme sahiptir.\n",
        "\n",
        "## 9. SHAP (XAI) Analiz SonuÃ§larÄ±\n",
        "\n",
        "SHAP (SHapley Additive exPlanations) analizi, Optuna ile optimize edilmiÅŸ modelin karar verme sÃ¼reÃ§lerini anlamak iÃ§in kullanÄ±lmÄ±ÅŸtÄ±r. Modelin 'Benign' sÄ±nÄ±fÄ±na (pozitif sÄ±nÄ±f) yÃ¶nelik tahminleri aÃ§Ä±klanmÄ±ÅŸtÄ±r.\n",
        "\n",
        "*   **Hangi Ã–zellikler KararlarÄ± Belirledi?**\n",
        "    *   **SHAP `summary_plot` ve `bar_plot`'a gÃ¶re en etkili Ã¶zellikler:** `worst perimeter`, `mean concave points`, `worst radius`, `worst area`, `mean radius`, `mean perimeter` ve `mean area` olarak sÄ±ralanmÄ±ÅŸtÄ±r. Bu Ã¶zellikler, tÃ¼mÃ¶rÃ¼n boyutu, ÅŸekli ve agresifliÄŸini yansÄ±tan Ã¶lÃ§Ã¼mler olup, modelin tahmin kararlarÄ± Ã¼zerinde en gÃ¼Ã§lÃ¼ etkiye sahiptir.\n",
        "    *   Ã–rneÄŸin, `worst perimeter`'Ä±n yÃ¼ksek deÄŸerleri modelin 'Malign' tahminini artÄ±rÄ±rken (veya 'Benign' tahminini azaltÄ±rken), dÃ¼ÅŸÃ¼k deÄŸerleri 'Benign' tahminini artÄ±rmaktadÄ±r.\n",
        "\n",
        "*   **Model Hangi Ã–zelliklere Daha DuyarlÄ±?**\n",
        "    *   Model, en yÃ¼ksek SHAP deÄŸerlerine sahip olan `worst perimeter` ve `mean concave points` gibi Ã¶zelliklerdeki kÃ¼Ã§Ã¼k deÄŸiÅŸimlere karÅŸÄ± en yÃ¼ksek duyarlÄ±lÄ±ÄŸÄ± gÃ¶stermektedir. Bu Ã¶zelliklerdeki deÄŸiÅŸiklikler, modelin tahmin Ã§Ä±ktÄ±sÄ±nda en bÃ¼yÃ¼k deÄŸiÅŸikliklere yol aÃ§maktadÄ±r.\n",
        "\n",
        "*   **GÃ¶zlemlenen SHAP Paternleri ve Biyolojik TutarlÄ±lÄ±k**:\n",
        "    *   **YÃ¶nlÃ¼ KatkÄ±**: Ã–zelliklerin modele katkÄ±larÄ± hem yÃ¶nlÃ¼ (pozitif veya negatif) hem de bÃ¼yÃ¼klÃ¼k olarak deÄŸiÅŸir. KÄ±rmÄ±zÄ± noktalar (yÃ¼ksek Ã¶zellik deÄŸeri) genellikle 'Malign' (daha dÃ¼ÅŸÃ¼k Benign olasÄ±lÄ±ÄŸÄ±) yÃ¶nde, mavi noktalar (dÃ¼ÅŸÃ¼k Ã¶zellik deÄŸeri) ise 'Benign' (daha yÃ¼ksek Benign olasÄ±lÄ±ÄŸÄ±) yÃ¶nde etki eder.\n",
        "    *   **Ã–zellik DeÄŸerine BaÄŸÄ±mlÄ±lÄ±k**: Bir Ã¶zelliÄŸin farklÄ± deÄŸerleri, tahmine farklÄ± yÃ¶nlerde ve bÃ¼yÃ¼klÃ¼klerde katkÄ±da bulunur.\n",
        "    *   **HiyerarÅŸik Ã–nem**: Modelin karar mekanizmasÄ±nda Ã¶zelliklerin belirgin bir hiyerarÅŸik Ã¶neme sahip olduÄŸu gÃ¶zlemlenmiÅŸtir.\n",
        "    *   **Biyolojik TutarlÄ±lÄ±k**: GÃ¶zlemlenen SHAP paternleri, meme kanseri biyolojisi ve teÅŸhisindeki klinik bilgilerle yÃ¼ksek dÃ¼zeyde tutarlÄ±dÄ±r. TÃ¼mÃ¶rÃ¼n boyutu, ÅŸekli ve hÃ¼cre morfolojisi ile ilgili Ã¶lÃ§Ã¼mlerin en Ã¶nemli belirleyiciler olmasÄ±, modelin biyolojik olarak anlamlÄ± desenleri yakaladÄ±ÄŸÄ±nÄ± gÃ¶stermiÅŸtir.\n",
        "    *   **`force_plot` ve `decision_plot`**: Bu gÃ¶rseller, tekil Ã¶rneklerin kararlarÄ±nÄ± temel deÄŸerden baÅŸlayarak Ã¶zelliklerin nasÄ±l kaydÄ±rdÄ±ÄŸÄ±nÄ± ve birden fazla Ã¶rneÄŸin karar yollarÄ±nÄ± gÃ¶stererek modelin kompleks etkileÅŸimlerini somutlaÅŸtÄ±rmÄ±ÅŸtÄ±r.\n",
        "\n",
        "Genel olarak, Optuna tarafÄ±ndan optimize edilmiÅŸ MLP modelimiz sadece yÃ¼ksek performanslÄ± olmakla kalmayÄ±p, aynÄ± zamanda kararlarÄ±nÄ± anlaÅŸÄ±lÄ±r ve yorumlanabilir Ã¶zellikler Ã¼zerine kurduÄŸunu ortaya koymaktadÄ±r. Bu ÅŸeffaflÄ±k, modelin klinik uygulamalar gibi hassas alanlarda kabul edilebilirliÄŸini artÄ±rabilir."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3lT4bD3Qat9wmdPdwQEYi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}